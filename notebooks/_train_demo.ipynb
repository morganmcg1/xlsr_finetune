{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y xlsr_finetune\n",
    "# !pip install -Uqqq git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -Uqqq git+https://github.com/huggingface/datasets.git\n",
    "# !pip install -Uqqq git+https://github.com/morganmcg1/xlsr_finetune.git\n",
    "# !pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlsr_finetune.data import *\n",
    "from xlsr_finetune.training import *\n",
    "from xlsr_finetune.wandbutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n",
      "Reusing dataset common_voice (../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset(\"common_voice\", \"ga-IE\", split=\"train+validation\", cache_dir=data_dir)\n",
    "valid_ds = load_dataset(\"common_voice\", \"ga-IE\", split=\"test\", cache_dir=data_dir)\n",
    "test_ds = valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"D\\'√≠sligh M√°ire ar a gl√∫ine le hais an chliabh√°in\"',\n",
       " 'An Phoblacht Dhoiminiceach',\n",
       " 'Gabhaim bu√≠ochas libh a chairde t√°imid ag tn√∫th le tuilleadh uaibh ar ball',\n",
       " 'Ar mhaith leat l√≥n?',\n",
       " 'An Nao√∫ Bliain',\n",
       " 'Go raibh maith agaibh agus bainig√≠ taitneamh as an bhfil√≠ocht agus as an gceol.',\n",
       " 'Gu√≠m gach rath agus beannacht oraibh don todhcha√≠',\n",
       " 'An mbeidh D√≥nall √ì Laoire anseo',\n",
       " 'An Cheardchomhairle.',\n",
       " 'Comhghairdeas libh go l√©ir agus gu√≠m gach rath oraibh sa todhcha√≠.',\n",
       " 'A dhaoine c√≥ra, a chairde d√≠lse,',\n",
       " 'Gura fada buan sibh i mbun cheol bhinn na h√âireann.',\n",
       " 'Is √≠ sin an obair at√° √° ceili√∫radh againn anocht',\n",
       " 'An Cl√°r',\n",
       " 'Mar a d√∫irt s√© f√©in',\n",
       " 'Titanic, B√©al Feirste, an seacht√∫ l√° de mh√≠ an Mh√°rta dh√° mh√≠le a c√∫ig d√©ag',\n",
       " 'An mbeidh siad ag obair anocht',\n",
       " '√âir√≠ as; Comhaltas a Fhionra√≠; Oibr√≠ochta√≠ a Fhionra√≠.',\n",
       " 'D‚Äôfh√©ach s√© ar an bhfrog',\n",
       " 'Airleacain √≥ √∫dar√°is tithe chun tithe a athfhoirgni√∫, a dheisi√∫ agus a fheabhs√∫.']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['sentence'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any rows where \"path\" doesn't contain a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if files have moved location between sessions, remap the path location\n",
    "# def remap_data_dir(e):\n",
    "#     e['path'] = f'{data_dir}/' + '/'.join(e['path'].split('/')[1:])\n",
    "#     return e\n",
    "\n",
    "# train_ds = train_ds.map(remap_data_dir)\n",
    "# valid_ds = valid_ds.map(remap_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-ac60caf50be0ec56.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-f7ccf59d7eefb8c0.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-29f7764b1cebe257.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-3c5e525f3a6edcad.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found\n",
      "All files found\n"
     ]
    }
   ],
   "source": [
    "train_ds = drop_missing_files(train_ds)\n",
    "valid_ds = drop_missing_files(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional] Merge another Dataset to Your training dataset and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ds = load_dataset(\"common_voice\", \"en\", split=\"test[20:40%]\", cache_dir=data_dir)\n",
    "# en_train_sample = load_dataset(\"common_voice\", \"en\", split=\"test\", cache_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ds = new_ds.map(remap_data_dir)\n",
    "# en_train_sample = en_train_sample.map(remap_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_ds = drop_missing_files(new_ds)\n",
    "# train_ds = merge_ds(train_ds, new_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jim O'Regan Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# So, tolower() for Irish is a bit complicated: tAthar -> t-athair\n",
    "# toupper() is non-deterministic :)\n",
    "def is_upper_vowel(letter):\n",
    "    if letter in ['A', 'E', 'I', 'O', 'U', '√Å', '√â', '√ç', '√ì', '√ö']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def irish_lower(word):\n",
    "    if len(word) > 1 and word[0] in ['n', 't'] and is_upper_vowel(word[1]):\n",
    "        return word[0] + '-' + word[1:].lower()\n",
    "    else:\n",
    "        return word.lower()\n",
    "    \n",
    "def irish_lower_sentence(sentence):\n",
    "    return \" \".join([irish_lower(w) for w in sentence.split(\" \")])\n",
    "\n",
    "chars_to_ignore_regex = '[,\\?\\.\\!\\;\\:\\\"\\‚Äú\\%\\‚Äò\\‚Äù\\(\\)\\*]'\n",
    "\n",
    "# def remove_special_characters(sentence):\n",
    "#     tmp = re.sub('‚Äô ', ' ', sentence)\n",
    "#     tmp = re.sub(\"‚Äô{{%htmlContent%}}quot;\", '', tmp)\n",
    "#     tmp = re.sub('‚Äô', '\\'', tmp)\n",
    "#     tmp = re.sub(chars_to_ignore_regex, '', tmp)\n",
    "#     sentence = irish_lower_sentence(tmp) + ' '\n",
    "#     return sentence\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    tmp = re.sub('‚Äô ', ' ', batch['sentence'])\n",
    "    tmp = re.sub(\"‚Äô{{%htmlContent%}}quot;\", '', tmp)\n",
    "    tmp = re.sub('‚Äô', '\\'', tmp)\n",
    "    \n",
    "    # MORGAN ADDED \"-\"\" regex\n",
    "    tmp = re.sub('[\\‚Äì]', '-', tmp)\n",
    "    tmp = re.sub('[\\‚Äî]', '-', tmp)\n",
    "    \n",
    "    tmp = re.sub(chars_to_ignore_regex, '', tmp)\n",
    "    batch['sentence'] = irish_lower_sentence(tmp) + ' '\n",
    "    return batch\n",
    "\n",
    "# # MINE!!\n",
    "# chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\‚Äú\\%\\‚Äò\\‚Äù\\ÔøΩ\\(\\)\\-\\*\\/\\\\\\]' \n",
    "# def remove_special_characters(batch, evaluate:bool=False, chars_to_ignore_regex:str=chars_to_ignore_regex):\n",
    "#     if evaluate: batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', \n",
    "#                                             batch[\"sentence\"]).lower()\n",
    "#     else: batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', \n",
    "#                                             batch[\"sentence\"]).lower() + \" \"\n",
    "        \n",
    "#     batch[\"sentence\"] = re.sub('[\\‚Äô]', '\\'', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[\\‚Äô]', '\\'', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[\\‚Äì]', '-', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[\\‚Äî]', '-', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[&]', ' and ', batch[\"sentence\"])\n",
    "#     return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data and create Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-447b03b5d4e9b362.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-62261d1474eea0fe.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(remove_special_characters)\n",
    "valid_ds = valid_ds.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"d'√≠sligh m√°ire ar a gl√∫ine le hais an chliabh√°in \",\n",
       " 'an phoblacht dhoiminiceach ',\n",
       " 'gabhaim bu√≠ochas libh a chairde t√°imid ag tn√∫th le tuilleadh uaibh ar ball ',\n",
       " 'ar mhaith leat l√≥n ',\n",
       " 'an nao√∫ bliain ',\n",
       " 'go raibh maith agaibh agus bainig√≠ taitneamh as an bhfil√≠ocht agus as an gceol ',\n",
       " 'gu√≠m gach rath agus beannacht oraibh don todhcha√≠ ',\n",
       " 'an mbeidh d√≥nall √≥ laoire anseo ',\n",
       " 'an cheardchomhairle ',\n",
       " 'comhghairdeas libh go l√©ir agus gu√≠m gach rath oraibh sa todhcha√≠ ',\n",
       " 'a dhaoine c√≥ra a chairde d√≠lse ',\n",
       " 'gura fada buan sibh i mbun cheol bhinn na h√©ireann ',\n",
       " 'is √≠ sin an obair at√° √° ceili√∫radh againn anocht ',\n",
       " 'an cl√°r ',\n",
       " 'mar a d√∫irt s√© f√©in ',\n",
       " 'titanic b√©al feirste an seacht√∫ l√° de mh√≠ an mh√°rta dh√° mh√≠le a c√∫ig d√©ag ',\n",
       " 'an mbeidh siad ag obair anocht ',\n",
       " '√©ir√≠ as comhaltas a fhionra√≠ oibr√≠ochta√≠ a fhionra√≠ ',\n",
       " \"d'fh√©ach s√© ar an bhfrog \",\n",
       " 'airleacain √≥ √∫dar√°is tithe chun tithe a athfhoirgni√∫ a dheisi√∫ agus a fheabhs√∫ ']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['sentence'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd13579f5b6e40f4afc019906290f952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e470d642ec6d48f1998e62b6b940cd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'j': 0,\n",
       " 'k': 1,\n",
       " 't': 2,\n",
       " 'r': 3,\n",
       " 'g': 4,\n",
       " '√©': 5,\n",
       " 'f': 6,\n",
       " '√≥': 7,\n",
       " 's': 8,\n",
       " 'e': 9,\n",
       " 'a': 11,\n",
       " 'v': 12,\n",
       " \"'\": 13,\n",
       " 'o': 14,\n",
       " 'h': 15,\n",
       " '√°': 16,\n",
       " 'c': 17,\n",
       " 'x': 18,\n",
       " 'w': 19,\n",
       " 'u': 20,\n",
       " 'b': 21,\n",
       " 'd': 22,\n",
       " 'l': 23,\n",
       " 'i': 24,\n",
       " 'm': 25,\n",
       " 'y': 26,\n",
       " 'n': 27,\n",
       " '√∫': 28,\n",
       " 'p': 29,\n",
       " '√≠': 30,\n",
       " '-': 31,\n",
       " '|': 10,\n",
       " '[UNK]': 32,\n",
       " '[PAD]': 33}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = extract_vocab(train_ds, valid_ds, save=True, save_dir='data')\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your vocab and add additional characters to ignore to the `chars_to_ignore_regex` string if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars_to_ignore_regex = chars_to_ignore_regex[:-1] + '\\ùìß]'\n",
    "# chars_to_ignore_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_remove_special_characters = partial(remove_special_characters, \n",
    "#                                         chars_to_ignore_regex=chars_to_ignore_regex)\n",
    "# train_ds = train_ds.map(new_remove_special_characters)\n",
    "# valid_ds = valid_ds.map(new_remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = extract_vocab(train_ds, valid_ds, save=True, save_dir='data')\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Audio to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2a = partial(speech_file_to_array, resample=True, new_sr=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-540b0b5f20a00d7e.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-e36f8c4ef762ef4e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-3487b66236ee960a.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-1a78b14c1c75739a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-b0e98eafe455de15.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-4ab87bb1d26ec961.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-9c5f5f0533a1626e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-cba1000c04901986.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-c48fb5fe6f3b74fa.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-5576375484537ddb.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-075427426b013895.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-b29ef75aaff84fde.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-7ce9e902e505f2f2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-a2c08ada0e8ce856.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-12a9d3d125caaaf0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-330e8b8cbf360325.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(sp2a, num_proc=8)\n",
    "valid_ds = valid_ds.map(sp2a, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Out Files That Could Not Be Read\n",
    "\n",
    "`speech_file_to_array` adds 0 to `speech` items where the path could not be read. Lets remove these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-96236c3cc8b36975.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 samples removed\n"
     ]
    }
   ],
   "source": [
    "prev_l = len(train_ds)\n",
    "train_ds = train_ds.filter(lambda example: len(example['speech'])>1, batch_size=1)\n",
    "print(f'{prev_l - len(train_ds)} samples removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out Long Audio in Training Set\n",
    "Longer audio can cause cuda oom errors, 112k frames @ 16k sample rate == 7s of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-0b3fb300b1905b1f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 samples out of 1038 removed\n"
     ]
    }
   ],
   "source": [
    "prev_l = len(train_ds)\n",
    "train_ds = train_ds.filter(lambda example: len(example['speech'])<=160_000) \n",
    "print(f'{prev_l - len(train_ds)} samples out of {prev_l} removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 1037\n",
      "Target text: t√° siad sa bhaile \n",
      "Input array shape: (41472,)\n",
      "Sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "rand_int = random.randint(0, len(train_ds)-1)\n",
    "\n",
    "print(f\"Number of train samples: {len(train_ds)}\")\n",
    "print(\"Target text:\", train_ds[rand_int][\"sentence\"])\n",
    "print(\"Input array shape:\", np.asarray(train_ds[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", train_ds[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"d'√≠sligh m√°ire ar a gl√∫ine le hais an chliabh√°in \",\n",
       " 'an phoblacht dhoiminiceach ',\n",
       " 'gabhaim bu√≠ochas libh a chairde t√°imid ag tn√∫th le tuilleadh uaibh ar ball ',\n",
       " 'ar mhaith leat l√≥n ',\n",
       " 'an nao√∫ bliain ',\n",
       " 'go raibh maith agaibh agus bainig√≠ taitneamh as an bhfil√≠ocht agus as an gceol ',\n",
       " 'gu√≠m gach rath agus beannacht oraibh don todhcha√≠ ',\n",
       " 'an mbeidh d√≥nall √≥ laoire anseo ',\n",
       " 'an cheardchomhairle ',\n",
       " 'comhghairdeas libh go l√©ir agus gu√≠m gach rath oraibh sa todhcha√≠ ',\n",
       " 'a dhaoine c√≥ra a chairde d√≠lse ',\n",
       " 'gura fada buan sibh i mbun cheol bhinn na h√©ireann ',\n",
       " 'is √≠ sin an obair at√° √° ceili√∫radh againn anocht ',\n",
       " 'an cl√°r ',\n",
       " 'mar a d√∫irt s√© f√©in ',\n",
       " 'titanic b√©al feirste an seacht√∫ l√° de mh√≠ an mh√°rta dh√° mh√≠le a c√∫ig d√©ag ',\n",
       " 'an mbeidh siad ag obair anocht ',\n",
       " '√©ir√≠ as comhaltas a fhionra√≠ oibr√≠ochta√≠ a fhionra√≠ ',\n",
       " \"d'fh√©ach s√© ar an bhfrog \",\n",
       " 'airleacain √≥ √∫dar√°is tithe chun tithe a athfhoirgni√∫ a dheisi√∫ agus a fheabhs√∫ ']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds['sentence'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess to Create Model Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"data/vocab.json\", unk_token=\"[UNK]\", \n",
    "                                 pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, \n",
    "                                          padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b35767fc8f04e10ad715be67bd233dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=33.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e3928bd5b54ff685e287c408a8cbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "# n_cpus = os.cpu_count() - 2\n",
    "\n",
    "train_ds = train_ds.map(prepare_dataset, remove_columns=train_ds.column_names, batch_size=32, batched=True)\n",
    "valid_ds = valid_ds.map(prepare_dataset, remove_columns=test_ds.column_names, batch_size=32, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Store Data in W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a W&B Run. You can now log any data you'd like to W&B Artifacts, and it will be tied to this Run. When we use `Trainer` this run will also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwandb\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie_grad-clip-0-05_jim-data_boris-hyp</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/f7qcnb8c\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/f7qcnb8c</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/xlsr_finetune/notebooks/wandb/run-20210328_170343-f7qcnb8c</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "entity, project = setup_wandb(entity='wandb', project_name='xlsr-irish', log_model=True)\n",
    "\n",
    "wandb_run = wandb.init(name='ie_grad-clip-0-05_jim-data_boris-hyp', project='xlsr-irish', entity='wandb', \n",
    "                       tags=['ie-en','baseline'], group='baseline', \n",
    "                       notes='Using the same data pre-processing and Jim O Regan, with Boris hyperparameters',\n",
    "                       reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./../../data/train_ready_train_ds)... Done. 6.2s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./../../data/train_ready_valid_ds)... Done. 3.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./../../data/raw_test_ds)... Done. 0.1s\n"
     ]
    }
   ],
   "source": [
    "# Log the datasets\n",
    "ds = {'train_ready_train_ds':train_ds,\n",
    "     'train_ready_valid_ds':valid_ds,\n",
    "     'raw_test_ds': test_ds,\n",
    "#      'raw_en_train_ds': en_train_sample\n",
    "     }\n",
    "\n",
    "for name in ds.keys():\n",
    "    f_path = f'../../data/{name}'\n",
    "    ds[name].save_to_disk(f_path)\n",
    "    artifact = wandb.Artifact(name=name, type='dataset',\n",
    "                             description='Same data pre-processing and Jim O Regan',\n",
    "                             metadata={'dataset_length':len(ds[name])})\n",
    "    artifact.add_dir(f_path)\n",
    "    wandb_run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7fca49c48190>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log vocab file\n",
    "vcb_f_path = 'data/vocab.json'\n",
    "artifact = wandb.Artifact(name='vocab', type='vocab', \n",
    "                          description='Vocab for combined ie and en, len 36',\n",
    "                          metadata={'vocab_length':len(vocab.keys())})\n",
    "artifact.add_file(vcb_f_path)\n",
    "wandb_run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7fca75fe8390>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log processor\n",
    "processor_path = './data'\n",
    "processor.save_pretrained(processor_path)\n",
    "artifact = wandb.Artifact(name='processor', type='processor')\n",
    "artifact.add_dir(processor_path)\n",
    "wandb_run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with wandb.init(project='xlsr-irish', entity='wandb') as run:\n",
    "#     # Connect an Artifact to your run\n",
    "#     train_ds_artifact = run.use_artifact('train_ready_train_ds:v0')\n",
    "# #     valid_ds_artifact = run.use_artifact('raw_en_train_ds:v0')\n",
    "\n",
    "#     # Download model weights to a folder and return the path\n",
    "#     train_ds_dir = train_ds_artifact.download()\n",
    "# #     valid_ds_dir = valid_ds_artifact.download()\n",
    "\n",
    "# # Load your Hugging Face model from that folder, e.g. SequenceClassification model\n",
    "# train_ds = load_from_disk(train_ds_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True,\n",
    "                                          pad_to_multiple_of=8, pad_to_multiple_of_labels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\",\n",
    "    activation_dropout= 0.055,\n",
    "    attention_dropout= 0.094,\n",
    "    hidden_dropout=0.047,\n",
    "    feat_proj_dropout= 0.04,\n",
    "    layerdrop=0.041,\n",
    "    mask_time_prob=0.082,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    ctc_zero_infinity=True,\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"../../data/my_xlsr\",\n",
    "  group_by_length=True,\n",
    "  max_grad_norm=0.05,\n",
    "  per_device_train_batch_size=32,\n",
    "  per_device_eval_batch_size=64,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  fp16=True,\n",
    "  save_steps=64,\n",
    "  eval_steps=64,\n",
    "  logging_steps=8,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=96,\n",
    "  save_total_limit=1,\n",
    "  dataloader_num_workers=16,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "#   run_name = 'ie-en_baseline_15e',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,    # Define \"best\" wer score as the lowest score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=partial(compute_wer_metric, processor=processor),   # compute_wer_metric imported from xlsr_finetune\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Monitoring [optional]\n",
    "Log in to Weights and Biases and set your entity (username) and project name, or else use the publicly available entity and project below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('wandb', 'xlsr-irish')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_wandb(entity='wandb', project_name='xlsr-irish', log_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='193' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [193/800 07:46 < 24:41, 0.41 it/s, Epoch 11.97/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.265500</td>\n",
       "      <td>3.162970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.368100</td>\n",
       "      <td>21.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.915900</td>\n",
       "      <td>2.911600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.557600</td>\n",
       "      <td>22.431000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>2.440300</td>\n",
       "      <td>2.278715</td>\n",
       "      <td>0.998830</td>\n",
       "      <td>22.243600</td>\n",
       "      <td>22.748000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# If using W&B and not doing any futher evaluation, then use wandb.finish()\n",
    "# wandb.finish()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wandb.finish** - If using W&B and not doing any futher training or evaluation, then use wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlsr_finetune.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset common_voice (../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "test_ds = load_dataset(\"common_voice\", \"ga-IE\", split=\"test\", cache_dir=data_dir)\n",
    "# test_ds = test_ds.map(remap_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8719a0a6f0034e7d8b0623fe196ef701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sp2a = partial(speech_file_to_array, resample=True, new_sr=16_000, evaluate=True)\n",
    "test_ds = test_ds.map(sp2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bc1ab21ce44c1598fab8e5e49e6cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ev = partial(evaluate_xlsr, model=model, processor=processor)\n",
    "result = test_ds.map(ev, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['bh√≠ tara bmhio sc√©ir√≠ agus meamh √≥ru√≥irc ag se√°int √≠ n√°irdinn nl√°',\n",
       "  't√° s√© anseo alais',\n",
       "  'bui deoar d ar naoion√°n na thircim cia s√∫in',\n",
       "  'an raibh na cail√≠ne ag obair',\n",
       "  'n√≠ raibh ac h√≠ uachtar aggam',\n",
       "  'go rabh mbeagaibh',\n",
       "  'ar dheis leabh d√© go roumhad anan d√≠lis',\n",
       "  'bh√≠o na tuonta i builh a goinne na gcairigithe',\n",
       "  't√° l√° is troca i m√≠nea nollaig',\n",
       "  'agus thug s√© a ch√∫lair goim√≠ cheadachagus dim√≠ s√©'],\n",
       " ['\"Bh√≠ Tara Viscardi agus Meadhbh O\\'Rourke ag seinnt i ngaird√≠n na mbl√°th\"',\n",
       "  'T√° s√© anseo anois',\n",
       "  'Ba ghearr go raibh an na√≠on√°n ina thoirchim suain',\n",
       "  'An raibh na cail√≠n√≠ ag obair',\n",
       "  'N√≠ raibh, ach bh√≠ uachtar agam',\n",
       "  'Go raibh maith agaibh',\n",
       "  'Ar dheis l√°mh D√© go raibh a anam d√≠lis',\n",
       "  'Bh√≠ na tonnta ag bualadh i gcoinne na gcarraigeacha.',\n",
       "  'T√° l√° is tr√≠ocha i m√≠ na Nollag',\n",
       "  'Agus thug s√© a ch√∫l air go m√≠-cheadtach agus d‚Äôimigh s√©'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:10][\"pred_strings\"], result[:10][\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 74.370977\n"
     ]
    }
   ],
   "source": [
    "wer_true = 100 * wer_metric.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])\n",
    "print(f\"WER: {wer_true:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# wandb_run.log({'test/wer_true': wer_true})\n",
    "# wandb_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jim O Regan Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "test_dataset = load_dataset(\"common_voice\", \"ga-IE\", split=\"test\")\n",
    "wer = load_metric(\"wer\")\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"jimregan/wav2vec2-large-xlsr-irish-basic\")\n",
    "# model = Wav2Vec2ForCTC.from_pretrained(\"jimregan/wav2vec2-large-xlsr-irish-basic\") \n",
    "# model.to(\"cuda\")\n",
    "\n",
    "# So, tolower() for Irish is a bit complicated: tAthar -> t-athair\n",
    "# toupper() is non-deterministic :)\n",
    "def is_upper_vowel(letter):\n",
    "    if letter in ['A', 'E', 'I', 'O', 'U', '√Å', '√â', '√ç', '√ì', '√ö']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def irish_lower(word):\n",
    "    if len(word) > 1 and word[0] in ['n', 't'] and is_upper_vowel(word[1]):\n",
    "        return word[0] + '-' + word[1:].lower()\n",
    "    else:\n",
    "        return word.lower()\n",
    "    \n",
    "def irish_lower_sentence(sentence):\n",
    "    return \" \".join([irish_lower(w) for w in sentence.split(\" \")])\n",
    "\n",
    "chars_to_ignore_regex = '[,\\?\\.\\!\\;\\:\\\"\\‚Äú\\%\\‚Äò\\‚Äù\\(\\)\\*]'\n",
    "\n",
    "def remove_special_characters(sentence):\n",
    "    tmp = re.sub('‚Äô ', ' ', sentence)\n",
    "    tmp = re.sub(\"‚Äô{{%htmlContent%}}quot;\", '', tmp)\n",
    "    tmp = re.sub('‚Äô', '\\'', tmp)\n",
    "    tmp = re.sub(chars_to_ignore_regex, '', tmp)\n",
    "    sentence = irish_lower_sentence(tmp) + ' '\n",
    "    return sentence\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the audio files as arrays\n",
    "def speech_file_to_array_fn(batch):\n",
    "    batch[\"sentence\"] = remove_special_characters(batch[\"sentence\"])\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "    return batch\n",
    "\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the audio files as arrays\n",
    "def evaluate(batch):\n",
    "    inputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits    \n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "    return batch\n",
    "    \n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=16)\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:10][\"pred_strings\"], result[:10][\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_true = 100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.log({'test/wer_true': wer_true})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
