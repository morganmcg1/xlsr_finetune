{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import re\n",
    "\n",
    "test_dataset = load_dataset(\"common_voice\", \"ie-GA\", split=\"test\") #TODO: replace {lang_id} in your language code here. Make sure the code is one of the *ISO codes* of [this](https://huggingface.co/languages) site.\n",
    "wer = load_metric(\"wer\")\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"data/checkpoint-975\") #TODO: replace {model_id} with your model id. The model id consists of {your_username}/{your_modelname}, *e.g.* `elgeish/wav2vec2-large-xlsr-53-arabic`\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"data/checkpoint-975}\") #TODO: replace {model_id} with your model id. The model id consists of {your_username}/{your_modelname}, *e.g.* `elgeish/wav2vec2-large-xlsr-53-arabic`\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“]'  # TODO: adapt this list to include all special characters you removed from the data\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\(\\)\\-\\*]'\n",
    "\n",
    "# MINE\n",
    "# chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\(\\)\\-\\*]'\n",
    "\n",
    "# def remove_special_characters(batch):\n",
    "#     batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "#     batch[\"sentence\"] = re.sub('[\\’]', '\\'', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[\\’]', '\\'', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[\\–]', '-', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[\\—]', '-', batch[\"sentence\"])\n",
    "#     batch[\"sentence\"] = re.sub('[&]', ' and ', batch[\"sentence\"])\n",
    "#     return batch\n",
    "\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(48_000, 16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays\n",
    "def speech_file_to_array_fn(batch):\n",
    "\tbatch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower()\n",
    "\tspeech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "\tbatch[\"speech\"] = resampler(speech_array).squeeze().numpy()\n",
    "\treturn batch\n",
    "\n",
    "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
    "\n",
    "# Preprocessing the datasets.\n",
    "# We need to read the aduio files as arrays\n",
    "def evaluate(batch):\n",
    "\tinputs = processor(batch[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tlogits = model(inputs.input_values.to(\"cuda\"), attention_mask=inputs.attention_mask.to(\"cuda\")).logits\n",
    "\n",
    "\tpred_ids = torch.argmax(logits, dim=-1)\n",
    "\tbatch[\"pred_strings\"] = processor.batch_decode(pred_ids)\n",
    "\treturn batch\n",
    "\n",
    "result = test_dataset.map(evaluate, batched=True, batch_size=8)\n",
    "\n",
    "print(\"WER: {:2f}\".format(100 * wer.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
