{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y xlsr_finetune\n",
    "# !pip install -Uqqq git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -Uqqq git+https://github.com/morganmcg1/xlsr_finetune.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlsr_finetune.data import *\n",
    "from xlsr_finetune.training import *\n",
    "from xlsr_finetune.wandbutils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor, Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n",
      "Reusing dataset common_voice (../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset(\"common_voice\", \"ga-IE\", split=\"train+validation\", cache_dir=data_dir)\n",
    "valid_ds = load_dataset(\"common_voice\", \"ga-IE\", split=\"test\", cache_dir=data_dir)\n",
    "test_ds = valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop any rows where \"path\" doesn't contain a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-86b23ad84e349908.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-d0027b289f39b354.arrow\n"
     ]
    }
   ],
   "source": [
    "# # if files have moved location between sessions, remap the path location\n",
    "# def remap_data_dir(e):\n",
    "#     e['path'] = f'{data_dir}/' + '/'.join(e['path'].split('/')[1:])\n",
    "#     return e\n",
    "\n",
    "# train_ds = train_ds.map(remap_data_dir)\n",
    "# valid_ds = valid_ds.map(remap_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-2683b0581eac87d8.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-f2c301a2d2b3595e.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-97f0418401e908ad.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-f8ff36573e42bd90.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found\n",
      "All files found\n"
     ]
    }
   ],
   "source": [
    "train_ds = drop_missing_files(train_ds)\n",
    "valid_ds = drop_missing_files(valid_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional] Merge another Dataset to Your training dataset and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (../../data/common_voice/en/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n"
     ]
    }
   ],
   "source": [
    "new_ds = load_dataset(\"common_voice\", \"en\", split=\"test[20:40%]\", cache_dir=data_dir)\n",
    "# en_train_sample = load_dataset(\"common_voice\", \"en\", split=\"test\", cache_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/en/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-769dfb14fdb4fbdb.arrow\n"
     ]
    }
   ],
   "source": [
    "new_ds = new_ds.map(remap_data_dir)\n",
    "# en_train_sample = en_train_sample.map(remap_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/en/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-3a6d8b4f90f0e2fe.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/en/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-f7ce85d3712c7519.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3c1d1845cd4becbb3907918501c66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_ds = drop_missing_files(new_ds)\n",
    "train_ds = merge_ds(train_ds, new_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data and create Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d49c6a8b0e43a995e01f7e51a60e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4271.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-94a50a5eaf5ba05b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(remove_special_characters)\n",
    "valid_ds = valid_ds.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c668687a21814be5a63e0daa36fa315e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4666482ef34a1eaa5cc370ab4b99d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'t': 0,\n",
       " 'Ã©': 1,\n",
       " 'a': 2,\n",
       " 'p': 3,\n",
       " 's': 4,\n",
       " 'x': 5,\n",
       " 'Ã­': 6,\n",
       " 'g': 7,\n",
       " 'r': 8,\n",
       " 'j': 9,\n",
       " 'u': 10,\n",
       " 'h': 11,\n",
       " 'y': 12,\n",
       " 'i': 13,\n",
       " 'b': 14,\n",
       " 'q': 15,\n",
       " 'c': 16,\n",
       " 'z': 17,\n",
       " 'w': 18,\n",
       " 'Ãº': 19,\n",
       " \"'\": 20,\n",
       " 'n': 21,\n",
       " '-': 22,\n",
       " 'd': 23,\n",
       " 'Ã³': 24,\n",
       " 'k': 25,\n",
       " 'o': 26,\n",
       " 'v': 27,\n",
       " 'Ã¡': 28,\n",
       " 'e': 29,\n",
       " 'm': 30,\n",
       " 'l': 32,\n",
       " 'f': 33,\n",
       " '|': 31,\n",
       " '[UNK]': 34,\n",
       " '[PAD]': 35}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = extract_vocab(train_ds, valid_ds, save=True, save_dir='data')\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your vocab and add additional characters to ignore to the `chars_to_ignore_regex` string if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\\\,\\\\?\\\\.\\\\!\\\\-\\\\;\\\\:\"\\\\â€œ\\\\%\\\\â€˜\\\\â€\\\\ï¿½\\\\(\\\\)\\\\-\\\\*\\\\/\\\\\\\\\\\\ð“§]'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_ignore_regex = chars_to_ignore_regex[:-1] + '\\ð“§]'\n",
    "chars_to_ignore_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57188f7a6f474248aeec64c35804378c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4271.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-d83bbd1bc3f17377.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_remove_special_characters = partial(remove_special_characters, \n",
    "                                        chars_to_ignore_regex=chars_to_ignore_regex)\n",
    "train_ds = train_ds.map(new_remove_special_characters)\n",
    "valid_ds = valid_ds.map(new_remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fa82944a604035a70e62d57cc54639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bd8b433b1e49248c4043530e0791fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'t': 0,\n",
       " 'Ã©': 1,\n",
       " 'a': 2,\n",
       " 'p': 3,\n",
       " 's': 4,\n",
       " 'x': 5,\n",
       " 'Ã­': 6,\n",
       " 'g': 7,\n",
       " 'r': 8,\n",
       " 'j': 9,\n",
       " 'u': 10,\n",
       " 'h': 11,\n",
       " 'y': 12,\n",
       " 'i': 13,\n",
       " 'b': 14,\n",
       " 'q': 15,\n",
       " 'c': 16,\n",
       " 'z': 17,\n",
       " 'w': 18,\n",
       " 'Ãº': 19,\n",
       " \"'\": 20,\n",
       " 'n': 21,\n",
       " 'd': 22,\n",
       " 'Ã³': 23,\n",
       " 'k': 24,\n",
       " 'o': 25,\n",
       " 'v': 26,\n",
       " 'Ã¡': 27,\n",
       " 'e': 28,\n",
       " 'm': 29,\n",
       " 'l': 31,\n",
       " 'f': 32,\n",
       " '|': 30,\n",
       " '[UNK]': 33,\n",
       " '[PAD]': 34}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = extract_vocab(train_ds, valid_ds, save=True, save_dir='data')\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Audio to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2a = partial(speech_file_to_array, resample=True, new_sr=16_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0e085107964f4b83c65d787513f01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61544cd669754e0f9fd56def510652a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452afd1093584a43b9736deb34d47c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc641d795ffe4b92a15df574d4f591be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#4', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b64c4f58fab4d91b9498316a8d7bda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05067202cdcb44239d6184567d90745c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#7', max=533.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0a4a89143144eeb6cc160d79f4856d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#5', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177fce855292427bbbe3751b5ef4047f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#6', max=534.0, style=ProgressStyle(description_width='inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-046b479ce551b5df.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-ab724829bc0fec12.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-b7d140b57de3c609.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-4b0056f882dd065e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-6527056f9e1a7b60.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-0725e80ba8042b9a.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-13653087c870bd2b.arrow\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-a4c0835ee167930e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_ds.map(sp2a, num_proc=8)\n",
    "valid_ds = valid_ds.map(sp2a, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Out Files That Could Not Be Read\n",
    "\n",
    "`speech_file_to_array` adds 0 to `speech` items where the path could not be read. Lets remove these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7050cf869b34a9484e06daad81a0990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4271.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 samples removed\n"
     ]
    }
   ],
   "source": [
    "prev_l = len(train_ds)\n",
    "train_ds = train_ds.filter(lambda example: len(example['speech'])>1, batch_size=1)\n",
    "print(f'{prev_l - len(train_ds)} samples removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out Long Audio in Training Set\n",
    "Longer audio can cause cuda oom errors, 112k frames @ 16k sample rate == 7s of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7920edea1462442dad8cc074e28e5297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "80 samples out of 4271 removed\n"
     ]
    }
   ],
   "source": [
    "prev_l = len(train_ds)\n",
    "train_ds = train_ds.filter(lambda example: len(example['speech'])<=160_000) \n",
    "print(f'{prev_l - len(train_ds)} samples out of {prev_l} removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 4191\n",
      "Target text: if we serve tea in crystal the shop is going to expand  \n",
      "Input array shape: (144000,)\n",
      "Sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "rand_int = random.randint(0, len(train_ds)-1)\n",
    "\n",
    "print(f\"Number of train samples: {len(train_ds)}\")\n",
    "print(\"Target text:\", train_ds[rand_int][\"sentence\"])\n",
    "print(\"Input array shape:\", np.asarray(train_ds[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", train_ds[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcess to Create Model Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"data/vocab.json\", unk_token=\"[UNK]\", \n",
    "                                 pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, \n",
    "                                          padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd02964f89e4a3bbb42536a77d2fc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=131.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a5012dfd144fa882f107005cbc2e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "# n_cpus = os.cpu_count() - 2\n",
    "\n",
    "train_ds = train_ds.map(prepare_dataset, remove_columns=train_ds.column_names, batch_size=32, batched=True)\n",
    "valid_ds = valid_ds.map(prepare_dataset, remove_columns=test_ds.column_names, batch_size=32, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Store Data in W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a W&B Run. You can now log any data you'd like to W&B Artifacts, and it will be tied to this Run. When we use `Trainer` this run will also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:  Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /workspace/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwandb\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie-en_baseline</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/1q03mh1a\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/1q03mh1a</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/xlsr_finetune/notebooks/wandb/run-20210327_150410-1q03mh1a</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "entity, project = setup_wandb(entity='wandb', project_name='xlsr-irish', log_model=True)\n",
    "\n",
    "wandb_run = wandb.init(name='ie-en_baseline', project='xlsr-irish', entity='wandb', \n",
    "                       tags=['ie-en','baseline'], group='baseline', reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./../../data/train_ready_train_ds)... Done. 7.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./../../data/train_ready_valid_ds)... Done. 1.7s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./../../data/raw_test_ds)... Done. 0.1s\n"
     ]
    }
   ],
   "source": [
    "# Log the datasets\n",
    "ds = {'train_ready_train_ds':train_ds,\n",
    "     'train_ready_valid_ds':valid_ds,\n",
    "     'raw_test_ds': test_ds,\n",
    "#      'raw_en_train_ds': en_train_sample\n",
    "     }\n",
    "\n",
    "for name in ds.keys():\n",
    "    f_path = f'../../data/{name}'\n",
    "    ds[name].save_to_disk(f_path)\n",
    "    artifact = wandb.Artifact(name=name, type='dataset',\n",
    "                             description='My dataset',\n",
    "                             metadata={'dataset_length':len(ds[name])})\n",
    "    artifact.add_dir(f_path)\n",
    "    wandb_run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f668dfe4f10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log vocab file\n",
    "vcb_f_path = 'data/vocab.json'\n",
    "artifact = wandb.Artifact(name='vocab', type='vocab', \n",
    "                          description='Vocab for combined ie and en, len 36',\n",
    "                          metadata={'vocab_length':len(vocab.keys())})\n",
    "artifact.add_file(vcb_f_path)\n",
    "wandb_run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./data)... Done. 0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_artifacts.Artifact at 0x7f668dd21cd0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log processor\n",
    "processor_path = './data'\n",
    "processor.save_pretrained(processor_path)\n",
    "artifact = wandb.Artifact(name='processor', type='processor')\n",
    "artifact.add_dir(processor_path)\n",
    "wandb_run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with wandb.init(project='xlsr-irish', entity='wandb') as run:\n",
    "#     # Connect an Artifact to your run\n",
    "#     train_ds_artifact = run.use_artifact('train_ready_train_ds:v0')\n",
    "# #     valid_ds_artifact = run.use_artifact('raw_en_train_ds:v0')\n",
    "\n",
    "#     # Download model weights to a folder and return the path\n",
    "#     train_ds_dir = train_ds_artifact.download()\n",
    "# #     valid_ds_dir = valid_ds_artifact.download()\n",
    "\n",
    "# # Load your Hugging Face model from that folder, e.g. SequenceClassification model\n",
    "# train_ds = load_from_disk(train_ds_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True,\n",
    "                                          pad_to_multiple_of=8, pad_to_multiple_of_labels=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d261d3116e0c4c4fb330ff8e30b1dc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1451.0, style=ProgressStyle(descriptionâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414cfe1920b94a7bbea9c1a9053d0bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1261920069.0, style=ProgressStyle(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    ctc_zero_infinity=True,\n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"../../data/my_xlsr\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=16,\n",
    "  gradient_accumulation_steps=4,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=30,\n",
    "  fp16=True,\n",
    "  save_steps=96,\n",
    "  eval_steps=64,\n",
    "  logging_steps=8,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=96,\n",
    "  save_total_limit=1,\n",
    "  dataloader_num_workers=16,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "  run_name = 'ie-en_baseline_15e',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,    # Define \"best\" wer score as the lowest score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=partial(compute_wer_metric, processor=processor),   # compute_wer_metric imported from xlsr_finetune\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=valid_ds,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Monitoring [optional]\n",
    "Log in to Weights and Biases and set your entity (username) and project name, or else use the publicly available entity and project below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('wandb', 'xlsr-irish')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_wandb(entity='wandb', project_name='xlsr-irish', log_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:760: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='3930' max='3930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3930/3930 4:56:59, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>3.253500</td>\n",
       "      <td>3.129127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.566700</td>\n",
       "      <td>11.614000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>2.994600</td>\n",
       "      <td>3.046782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.413200</td>\n",
       "      <td>11.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>2.922000</td>\n",
       "      <td>2.945201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.114500</td>\n",
       "      <td>11.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>2.855300</td>\n",
       "      <td>2.858851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>43.455700</td>\n",
       "      <td>11.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.285200</td>\n",
       "      <td>2.151958</td>\n",
       "      <td>0.997951</td>\n",
       "      <td>43.955200</td>\n",
       "      <td>11.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>1.702600</td>\n",
       "      <td>1.730614</td>\n",
       "      <td>1.036289</td>\n",
       "      <td>44.519900</td>\n",
       "      <td>11.366000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>1.304600</td>\n",
       "      <td>1.430131</td>\n",
       "      <td>0.896693</td>\n",
       "      <td>44.174700</td>\n",
       "      <td>11.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>1.136300</td>\n",
       "      <td>1.291219</td>\n",
       "      <td>0.892596</td>\n",
       "      <td>44.950100</td>\n",
       "      <td>11.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.946400</td>\n",
       "      <td>1.267455</td>\n",
       "      <td>0.856014</td>\n",
       "      <td>44.606000</td>\n",
       "      <td>11.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.924600</td>\n",
       "      <td>1.145469</td>\n",
       "      <td>0.812116</td>\n",
       "      <td>43.526700</td>\n",
       "      <td>11.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>1.016425</td>\n",
       "      <td>0.803336</td>\n",
       "      <td>44.575200</td>\n",
       "      <td>11.352000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.791200</td>\n",
       "      <td>0.988588</td>\n",
       "      <td>0.778168</td>\n",
       "      <td>44.673400</td>\n",
       "      <td>11.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>832</td>\n",
       "      <td>0.699700</td>\n",
       "      <td>1.057331</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>45.253500</td>\n",
       "      <td>11.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>0.667900</td>\n",
       "      <td>1.047246</td>\n",
       "      <td>0.771144</td>\n",
       "      <td>47.138000</td>\n",
       "      <td>10.734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>0.961794</td>\n",
       "      <td>0.731636</td>\n",
       "      <td>45.156700</td>\n",
       "      <td>11.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.650100</td>\n",
       "      <td>1.006251</td>\n",
       "      <td>0.791630</td>\n",
       "      <td>44.984500</td>\n",
       "      <td>11.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1088</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.988849</td>\n",
       "      <td>0.745976</td>\n",
       "      <td>45.662200</td>\n",
       "      <td>11.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1152</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>1.008517</td>\n",
       "      <td>0.709102</td>\n",
       "      <td>47.197600</td>\n",
       "      <td>10.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1216</td>\n",
       "      <td>0.458900</td>\n",
       "      <td>1.005676</td>\n",
       "      <td>0.733099</td>\n",
       "      <td>45.871600</td>\n",
       "      <td>11.031000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>1.014435</td>\n",
       "      <td>0.741294</td>\n",
       "      <td>45.531700</td>\n",
       "      <td>11.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1344</td>\n",
       "      <td>0.383600</td>\n",
       "      <td>0.993548</td>\n",
       "      <td>0.728124</td>\n",
       "      <td>46.395100</td>\n",
       "      <td>10.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1408</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>1.004270</td>\n",
       "      <td>0.720222</td>\n",
       "      <td>45.452100</td>\n",
       "      <td>11.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1472</td>\n",
       "      <td>0.330100</td>\n",
       "      <td>1.005934</td>\n",
       "      <td>0.713784</td>\n",
       "      <td>46.700600</td>\n",
       "      <td>10.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1536</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.969467</td>\n",
       "      <td>0.688323</td>\n",
       "      <td>45.396700</td>\n",
       "      <td>11.146000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>1.122993</td>\n",
       "      <td>0.705297</td>\n",
       "      <td>45.806800</td>\n",
       "      <td>11.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1664</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>1.004920</td>\n",
       "      <td>0.692420</td>\n",
       "      <td>47.772500</td>\n",
       "      <td>10.592000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1728</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>1.039006</td>\n",
       "      <td>0.689494</td>\n",
       "      <td>47.891400</td>\n",
       "      <td>10.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1792</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>1.018236</td>\n",
       "      <td>0.682177</td>\n",
       "      <td>45.780400</td>\n",
       "      <td>11.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1856</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>1.061188</td>\n",
       "      <td>0.704419</td>\n",
       "      <td>47.061200</td>\n",
       "      <td>10.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.260900</td>\n",
       "      <td>1.026913</td>\n",
       "      <td>0.690372</td>\n",
       "      <td>45.937400</td>\n",
       "      <td>11.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1984</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>1.145641</td>\n",
       "      <td>0.678665</td>\n",
       "      <td>46.531300</td>\n",
       "      <td>10.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2048</td>\n",
       "      <td>0.245400</td>\n",
       "      <td>1.192525</td>\n",
       "      <td>0.693006</td>\n",
       "      <td>46.378000</td>\n",
       "      <td>10.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2112</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1.128257</td>\n",
       "      <td>0.667545</td>\n",
       "      <td>46.713100</td>\n",
       "      <td>10.832000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2176</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.104616</td>\n",
       "      <td>0.660228</td>\n",
       "      <td>48.670100</td>\n",
       "      <td>10.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>1.147484</td>\n",
       "      <td>0.668423</td>\n",
       "      <td>46.312700</td>\n",
       "      <td>10.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2304</td>\n",
       "      <td>0.218500</td>\n",
       "      <td>1.113456</td>\n",
       "      <td>0.657887</td>\n",
       "      <td>47.781800</td>\n",
       "      <td>10.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2368</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>1.125123</td>\n",
       "      <td>0.669301</td>\n",
       "      <td>45.832500</td>\n",
       "      <td>11.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2432</td>\n",
       "      <td>0.204200</td>\n",
       "      <td>1.205310</td>\n",
       "      <td>0.680421</td>\n",
       "      <td>47.111200</td>\n",
       "      <td>10.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2496</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>1.201123</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>48.216900</td>\n",
       "      <td>10.494000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>1.152783</td>\n",
       "      <td>0.676910</td>\n",
       "      <td>46.620800</td>\n",
       "      <td>10.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2624</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>1.172205</td>\n",
       "      <td>0.661106</td>\n",
       "      <td>47.414100</td>\n",
       "      <td>10.672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2688</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>1.175710</td>\n",
       "      <td>0.640035</td>\n",
       "      <td>50.857300</td>\n",
       "      <td>9.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2752</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>1.192633</td>\n",
       "      <td>0.652034</td>\n",
       "      <td>52.305600</td>\n",
       "      <td>9.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2816</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>1.123655</td>\n",
       "      <td>0.641498</td>\n",
       "      <td>51.206700</td>\n",
       "      <td>9.882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.185200</td>\n",
       "      <td>1.175112</td>\n",
       "      <td>0.647937</td>\n",
       "      <td>51.863200</td>\n",
       "      <td>9.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2944</td>\n",
       "      <td>0.131100</td>\n",
       "      <td>1.222811</td>\n",
       "      <td>0.665203</td>\n",
       "      <td>49.240200</td>\n",
       "      <td>10.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3008</td>\n",
       "      <td>0.103900</td>\n",
       "      <td>1.268535</td>\n",
       "      <td>0.638865</td>\n",
       "      <td>48.427000</td>\n",
       "      <td>10.449000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3072</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>1.251258</td>\n",
       "      <td>0.637694</td>\n",
       "      <td>48.112800</td>\n",
       "      <td>10.517000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3136</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>1.238169</td>\n",
       "      <td>0.642669</td>\n",
       "      <td>48.999900</td>\n",
       "      <td>10.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.117200</td>\n",
       "      <td>1.223174</td>\n",
       "      <td>0.630963</td>\n",
       "      <td>48.992800</td>\n",
       "      <td>10.328000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3264</td>\n",
       "      <td>0.131200</td>\n",
       "      <td>1.240813</td>\n",
       "      <td>0.636231</td>\n",
       "      <td>48.362300</td>\n",
       "      <td>10.463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3328</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>1.210284</td>\n",
       "      <td>0.646181</td>\n",
       "      <td>49.954900</td>\n",
       "      <td>10.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3392</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>1.226963</td>\n",
       "      <td>0.645888</td>\n",
       "      <td>48.920300</td>\n",
       "      <td>10.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3456</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>1.255604</td>\n",
       "      <td>0.640035</td>\n",
       "      <td>48.346400</td>\n",
       "      <td>10.466000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>1.260563</td>\n",
       "      <td>0.640620</td>\n",
       "      <td>48.490600</td>\n",
       "      <td>10.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3584</td>\n",
       "      <td>0.108400</td>\n",
       "      <td>1.255241</td>\n",
       "      <td>0.641498</td>\n",
       "      <td>48.973400</td>\n",
       "      <td>10.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3648</td>\n",
       "      <td>0.116200</td>\n",
       "      <td>1.248283</td>\n",
       "      <td>0.630085</td>\n",
       "      <td>48.691800</td>\n",
       "      <td>10.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3712</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>1.250142</td>\n",
       "      <td>0.635645</td>\n",
       "      <td>49.267600</td>\n",
       "      <td>10.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3776</td>\n",
       "      <td>0.125300</td>\n",
       "      <td>1.258377</td>\n",
       "      <td>0.625110</td>\n",
       "      <td>48.976600</td>\n",
       "      <td>10.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>1.264738</td>\n",
       "      <td>0.625988</td>\n",
       "      <td>48.620400</td>\n",
       "      <td>10.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3904</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>1.269477</td>\n",
       "      <td>0.626573</td>\n",
       "      <td>50.242700</td>\n",
       "      <td>10.071000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3930, training_loss=0.6994878225805802, metrics={'train_runtime': 17816.8342, 'train_samples_per_second': 0.221, 'total_flos': 1.9599395248616518e+19, 'epoch': 30.0, 'init_mem_cpu_alloc_delta': 69259, 'init_mem_gpu_alloc_delta': 1261898752, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 0, 'train_mem_gpu_alloc_delta': 5107040768, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# If using W&B and not doing any futher evaluation, then use wandb.finish()\n",
    "# wandb.finish()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**wandb.finish** - If using W&B and not doing any futher training or evaluation, then use wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlsr_finetune.evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f)\n",
      "Loading cached processed dataset at ../../data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-d0027b289f39b354.arrow\n"
     ]
    }
   ],
   "source": [
    "test_ds = load_dataset(\"common_voice\", \"ga-IE\", split=\"test\", cache_dir=data_dir)\n",
    "test_ds = test_ds.map(remap_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833b1a50fb8d4c56aa56242bc22c9535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sp2a = partial(speech_file_to_array, resample=True, new_sr=16_000, evaluate=True)\n",
    "test_ds = test_ds.map(sp2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5feabfb89b284519a5210f7a0b4fe046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ev = partial(evaluate_xlsr, model=model, processor=processor)\n",
    "result = test_ds.map(ev, batched=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 81.275600\n"
     ]
    }
   ],
   "source": [
    "wer_true = 100 * wer_metric.compute(predictions=result[\"pred_strings\"], references=result[\"sentence\"])\n",
    "print(f\"WER: {wer_true:2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39924<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4296.73MB of 4296.73MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/workspace/xlsr_finetune/notebooks/wandb/run-20210327_150410-1q03mh1a/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/workspace/xlsr_finetune/notebooks/wandb/run-20210327_150410-1q03mh1a/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.1413</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/epoch</td><td>30.0</td></tr><tr><td>train/global_step</td><td>3930</td></tr><tr><td>_runtime</td><td>23309</td></tr><tr><td>_timestamp</td><td>1616880760</td></tr><tr><td>_step</td><td>553</td></tr><tr><td>eval/loss</td><td>1.26948</td></tr><tr><td>eval/wer</td><td>0.62657</td></tr><tr><td>eval/runtime</td><td>50.2427</td></tr><tr><td>eval/samples_per_second</td><td>10.071</td></tr><tr><td>train/train_runtime</td><td>17816.8342</td></tr><tr><td>train/train_samples_per_second</td><td>0.221</td></tr><tr><td>train/total_flos</td><td>1.9599395248616518e+19</td></tr><tr><td>test/wer_true</td><td>81.2756</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ƒâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>train/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_runtime</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_timestamp</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>eval/loss</td><td>â–ˆâ–ˆâ–‡â–…â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>eval/wer</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>eval/runtime</td><td>â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–…â–…â–ƒâ–…â–„â–‡â–‡â–ˆâ–…â–…â–†â–…â–†â–…â–†â–…â–†â–‡</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–†â–…â–‡â–†â–†â–…â–†â–†â–†â–„â–†â–†â–…â–…â–ƒâ–„â–†â–„â–„â–‚â–â–â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚</td></tr><tr><td>train/train_runtime</td><td>â–</td></tr><tr><td>train/train_samples_per_second</td><td>â–</td></tr><tr><td>train/total_flos</td><td>â–</td></tr><tr><td>test/wer_true</td><td>â–</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 1 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ie-en_baseline</strong>: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/1q03mh1a\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/1q03mh1a</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb_run.log({'test/wer_true': wer_true})\n",
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# wandb.log({'test/wer_true': wer_true})\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
