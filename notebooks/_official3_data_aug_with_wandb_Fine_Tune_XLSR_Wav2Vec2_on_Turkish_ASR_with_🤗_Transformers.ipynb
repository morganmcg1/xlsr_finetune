{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Exploration - Fine-tuning XLSR-Wav2Vec2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets==1.4.1\n",
    "# !pip install transformers==4.4.0\n",
    "!pip install torchaudio\n",
    "!pip install librosa\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_ENTITY=wandb\n",
      "env: WANDB_PROJECT=xlsr-irish\n",
      "env: WANDB_LOG_MODEL=true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "# W&B company account\n",
    "%env WANDB_ENTITY = wandb\n",
    "entity = os.environ[\"WANDB_ENTITY\"]\n",
    "\n",
    "# Choose the public W&B project\n",
    "%env WANDB_PROJECT = xlsr-irish\n",
    "project_name = os.environ[\"WANDB_PROJECT\"]\n",
    "\n",
    "# Log your trained model to W&B as an Artifact\n",
    "%env WANDB_LOG_MODEL = true "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmorgan-test\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data, Tokenizer, Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset common_voice/ga-IE (download: 149.30 MiB, generated: 1.53 MiB, post-processed: Unknown size, total: 150.83 MiB) to data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b54c11eafe94126b8dbf99b327caec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=156553447.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset common_voice downloaded and prepared to data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f. Subsequent calls will reuse this data.\n",
      "Downloading and preparing dataset common_voice/ga-IE (download: 149.30 MiB, generated: 1.53 MiB, post-processed: Unknown size, total: 150.83 MiB) to data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d1d9b6a4254b1aa3e857003abe42b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=156553447.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset common_voice downloaded and prepared to data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "# common_voice_train = load_dataset(\"common_voice\", \"tr\", split=\"train+validation\", cache_dir='data')\n",
    "# common_voice_test = load_dataset(\"common_voice\", \"tr\", split=\"test\", cache_dir='data')\n",
    "\n",
    "common_voice_train = load_dataset(\"common_voice\", \"ga-IE\", split=\"train+validation\", cache_dir='data',\n",
    "                                 download_mode='force_redownload')\n",
    "common_voice_test = load_dataset(\"common_voice\", \"ga-IE\", split=\"test\", cache_dir='data',\n",
    "                                download_mode='force_redownload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "     num_rows: 1038\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
       "     num_rows: 506\n",
       " }))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_train, common_voice_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many ASR datasets only provide the target text, `'sentence'` for each audio file `'path'`. Common Voice actually provides much more information about each audio file, such as the `'accent'`, etc. However, we want to keep the notebook as general as possible, so that we will only consider the transcribed text for fine-tuning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_voice_train = common_voice_train.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])\n",
    "# common_voice_test = common_voice_test.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"segment\", \"up_votes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\(\\)\\*]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower() + \" \"\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c88b0890a5b498188f1fcb6b854628e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1038.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bab2d22959e4bafb70609e07d873c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=506.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(remove_special_characters)\n",
    "common_voice_test = common_voice_test.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_chars(batch):\n",
    "  all_text = \" \".join(batch[\"sentence\"])\n",
    "  vocab = list(set(all_text))\n",
    "  return {\"vocab\": [vocab], \"all_text\": [all_text]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9beea6dfff4131957b3bba3ff88a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8b21cc283b4f1b9804f923dd58561f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab_train = common_voice_train.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_train.column_names)\n",
    "vocab_test = common_voice_test.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=common_voice_test.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create the union of all distinct letters in the training dataset and test dataset and convert the resulting list into an enumerated dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(set(vocab_train[\"vocab\"][0]) | set(vocab_test[\"vocab\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33,\n",
       " {'b': 0,\n",
       "  '’': 1,\n",
       "  'i': 2,\n",
       "  'm': 3,\n",
       "  'ú': 4,\n",
       "  'f': 5,\n",
       "  '–': 6,\n",
       "  'g': 7,\n",
       "  'p': 8,\n",
       "  'r': 9,\n",
       "  'w': 10,\n",
       "  'í': 11,\n",
       "  't': 12,\n",
       "  'c': 13,\n",
       "  'v': 14,\n",
       "  'u': 15,\n",
       "  'k': 16,\n",
       "  'x': 17,\n",
       "  'e': 18,\n",
       "  'y': 19,\n",
       "  'h': 20,\n",
       "  'é': 21,\n",
       "  's': 22,\n",
       "  'a': 23,\n",
       "  'n': 24,\n",
       "  'á': 25,\n",
       "  'd': 26,\n",
       "  'o': 27,\n",
       "  'l': 28,\n",
       "  ' ': 29,\n",
       "  'ó': 30,\n",
       "  'j': 31,\n",
       "  \"'\": 32})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
    "len(vocab_dict.keys()), vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we see that all letters of the alphabet occur in the dataset (which is not really surprising) and we also extracted the special characters `\" \"` and `'`. Note that we did not exclude those special characters because: \n",
    "\n",
    "- The model has to learn to predict when a word is finished or else the model prediction would always be a sequence of chars which would make it impossible to separate words from each other.\n",
    "- From the transcriptions above it seems that words that include an apostrophe, such as `maktouf'un` do exist in Turkish, so I decided to keep the apostrophe in the dataset. This might be a wrong assumption though.\n",
    "\n",
    "One should always keep in mind that the data-preprocessing is a very important step before training your model. E.g., we don't want our model to differentiate between `a` and `A` just because we forgot to normalize the data. The difference between `a` and `A` does not depend on the \"sound\" of the letter at all, but more on grammatical rules - *e.g.* use a capitalized letter at the beginning of the sentence. So it is sensible to remove the difference between capitalized and non-capitalized letters so that the model has an easier time learning to transcribe speech. \n",
    "\n",
    "It is always advantageous to get help from a native speaker of the language you would like to transcribe to verify whether the assumptions you made are sensible, *e.g.* I should have made sure that keeping `'`, but removing other special characters is a sensible choice for Turkish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it clearer that `\" \"` has its own token class, we give it a more visible character `|`. In addition, we also add an \"unknown\" token so that the model can later deal with characters not encountered in Common Voice's training set. \n",
    "\n",
    "Finally, we also add a padding token that corresponds to CTC's \"*blank token*\". The \"blank token\" is a core component of the CTC algorithm. For more information, please take a look at the \"Alignment\" section [here](https://distill.pub/2017/ctc/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "len(vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 0,\n",
       " '’': 1,\n",
       " 'i': 2,\n",
       " 'm': 3,\n",
       " 'ú': 4,\n",
       " 'f': 5,\n",
       " '–': 6,\n",
       " 'g': 7,\n",
       " 'p': 8,\n",
       " 'r': 9,\n",
       " 'w': 10,\n",
       " 'í': 11,\n",
       " 't': 12,\n",
       " 'c': 13,\n",
       " 'v': 14,\n",
       " 'u': 15,\n",
       " 'k': 16,\n",
       " 'x': 17,\n",
       " 'e': 18,\n",
       " 'y': 19,\n",
       " 'h': 20,\n",
       " 'é': 21,\n",
       " 's': 22,\n",
       " 'a': 23,\n",
       " 'n': 24,\n",
       " 'á': 25,\n",
       " 'd': 26,\n",
       " 'o': 27,\n",
       " 'l': 28,\n",
       " 'ó': 30,\n",
       " 'j': 31,\n",
       " \"'\": 32,\n",
       " '|': 29,\n",
       " '[UNK]': 33,\n",
       " '[PAD]': 34}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now our vocabulary is complete and consists of 39 tokens, which means that the linear layer that we will add on top of the pretrained XLSR-Wav2Vec2 checkpoint will have an output dimension of 39."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now save the vocabulary as a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('vocab.json', 'w') as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final step, we use the json file to instantiate an object of the `Wav2Vec2CTCTokenizer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create the feature extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create XLSR-Wav2Vec2 Feature Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech is a continuous signal and to be treated by computers, it first has to be discretized, which is usually called **sampling**. The sampling rate hereby plays an important role in that it defines how many data points of the speech signal are measured per second. Therefore, sampling with a higher sampling rate results in a better approximation of the *real* speech signal but also necessitates more values per second.\n",
    "\n",
    "A pretrained checkpoint expects its input data to have been sampled more or less from the same distribution as the data it was trained on. The same speech signals sampled at two different rates have a very different distribution, *e.g.*, doubling the sampling rate results in data points being twice as long. Thus, \n",
    "before fine-tuning a pretrained checkpoint of an ASR model, it is crucial to verify that the sampling rate of the data that was used to pretrain the model matches the sampling rate of the dataset used to fine-tune the model.\n",
    "\n",
    "XLSR-Wav2Vec2 was pretrained on the audio data of [Babel](https://huggingface.co/datasets/librispeech_asr), \n",
    "[Multilingual LibriSpeech (MLS)](https://ai.facebook.com/blog/a-new-open-data-set-for-multilingual-speech-research/), and [Common Voice](https://huggingface.co/datasets/common_voice). Most of those datasets were sampled at 16kHz, so that Common Voice, sampled at 48kHz, has to be downsampled to 16kHz for training. Therefore, we will have to downsample our fine-tuning data to 16kHz in the following.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A XLSR-Wav2Vec2 feature extractor object requires the following parameters to be instantiated:\n",
    "\n",
    "- `feature_size`: Speech models take a sequence of feature vectors as an input. While the length of this sequence obviously varies, the feature size should not. In the case of Wav2Vec2, the feature size is 1 because the model was trained on the raw speech signal ${}^2$.\n",
    "- `sampling_rate`: The sampling rate at which the model is trained on.\n",
    "- `padding_value`: For batched inference, shorter inputs need to be padded with a specific value\n",
    "- `do_normalize`: Whether the input should be *zero-mean-unit-variance* normalized or not. Usually, speech models perform better when normalizing the input\n",
    "- `return_attention_mask`: Whether the model should make use of an `attention_mask` for batched inference. In general, XLSR-Wav2Vec2 models should **always** make use of the `attention_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, XLSR-Wav2Vec2's feature extraction pipeline is thereby fully defined!\n",
    "\n",
    "To make the usage of XLSR-Wav2Vec2 as user-friendly as possible, the feature extractor and tokenizer are *wrapped* into a single `Wav2Vec2Processor` class so that one only needs a `model` and `processor` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wants to re-use the just created processor and the fine-tuned model of this notebook, one can mount his/her google drive to the notebook and save all relevant files there. To do so, please uncomment the following lines. \n",
    "\n",
    "We will give the fine-tuned model the name `\"wav2vec2-large-xlsr-turkish-demo\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.save_pretrained(\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-turkish-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can prepare the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data\n",
    "\n",
    "So far, we have not looked at the actual values of the speech signal but just kept the path to its file in the dataset. `XLSR-Wav2Vec2` expects the audio file in the format of a 1-dimensional array, so in the first step, let's load all audio files into the dataset object.\n",
    "\n",
    "Let's first check the serialization format of the downloaded audio files by looking at the first training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accent': 'mumhain',\n",
       " 'age': 'twenties',\n",
       " 'client_id': '2bf1907838353bd4ff938cb357518af5cd662218dcf4e05e91bccb5c4981619def6e13f25156c63c468ac5e938051eb89983ae095606bc1ebcbe2aba77dbcf38',\n",
       " 'down_votes': 0,\n",
       " 'gender': 'male',\n",
       " 'locale': 'ga-IE',\n",
       " 'path': 'data/downloads/extracted/15a74a5b82f1f8ab9fbbd4abdaf1812f284ed478c2987d3a597b7a96d15e67a7/cv-corpus-6.1-2020-12-11/ga-IE/clips/common_voice_ga-IE_18183217.mp3',\n",
       " 'segment': \"''\",\n",
       " 'sentence': \"d'ísligh máire ar a glúine le hais an chliabháin \",\n",
       " 'up_votes': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, the audio file is saved in the `.mp3` format. The `.mp3` format is usually not the easiest format to deal with. We found that the [`torchaudio`](https://pytorch.org/audio/stable/index.html) library works best for reading in `.mp3` data. \n",
    "\n",
    "An audio file usually stores both its values and the sampling rate with which the speech signal was digitalized. We want to store both in the dataset and write a `map(...)` function accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WANDB: Log Baseline Audio + Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchaudio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Init:\n",
    "\n",
    "$ sudo apt update\n",
    "$ sudo apt install ffmpeg\n",
    "\n",
    "ffmpeg -i /home/rubens/audio_test.wav -ac 1 -ab 8k audio_test2.wav\n",
    "# encoding=enums.RecognitionConfig.AudioEncoding.MULAW\n",
    "\n",
    "-ac – Set the number of audio channels (1,2)\n",
    "-ab – Indicates the audio bitrate (8k, 128k, 256k)\n",
    "-ar – Set the audio frequency of the output file (22050, 44100, 48000 Hz)\n",
    "-filter:a\n",
    "\n",
    "THIS **\n",
    "\n",
    "ffmpeg -i ./convert.wav -ac 2 -ab 128k -filter:a volume=0.95 -filter:a equalizer=f=4000:t=h:w=1:g=-5 -filter:a dynaudnorm audio_norm.wav\n",
    "\n",
    "ffmpeg -i audio_norm.wav -af silenceremove=1:0:-50dB output.mp3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ffmpeg -i 123451003938384-Original.wav -ac 1 -ab 128k audio_transform_iac_1ab128k.wav\n",
    "# encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "\n",
    "ffmpeg -i /home/rubens/audio.mp3 -ac 2   \n",
    "\n",
    "ffmpeg -i /home/rubens/audio.mp3 -ac 2 -ab 128k -filter:a volume=0.95 -filter:a equalizer=f=4000:t=h:w=1:g=-5 -filter:a dynaudnorm audio_norm2.wav  \n",
    "\n",
    "ffmpeg -i /home/rubens/audio_norm2.wav -map_channel 0.0.0 output_left.wav  \n",
    "\n",
    "ffmpeg -ss 00:00:00 -to 00:05:00 -i audio-original.mp3 audio-cortado.mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyloudnorm\n",
      "  Downloading pyloudnorm-0.1.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from pyloudnorm) (1.4.1)\n",
      "Requirement already satisfied: future>=0.16.0 in /opt/conda/lib/python3.7/site-packages (from pyloudnorm) (0.18.2)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /opt/conda/lib/python3.7/site-packages (from pyloudnorm) (1.18.5)\n",
      "Installing collected packages: pyloudnorm\n",
      "Successfully installed pyloudnorm-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyloudnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4807e-05, 2.4311e-05,\n",
       "        2.4389e-05])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3219)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.max(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(data[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32192686"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32192686"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(data[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , ..., 0.00034731, 0.00033315,\n",
       "       0.00030224], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loudness_normalized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1106150110>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loudness_normalized_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([145536])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f110613d350>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sa[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159360])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(loudness_normalized_audio).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 159360]), (159360,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "\n",
    "def get_loudness_normalised(sa, sr):\n",
    "    # peak normalize audio to -1 dB\n",
    "    peak_normalized_audio = pyln.normalize.peak(sa, -1.0)\n",
    "\n",
    "    # measure the loudness first \n",
    "    meter = pyln.Meter(rate) # create BS.1770 meter\n",
    "    loudness = meter.integrated_loudness(sa)\n",
    "\n",
    "    # loudness normalize audio to -12 dB LUFS\n",
    "    loudness_normalized_audio = pyln.normalize.loudness(sa, loudness, -12.0)\n",
    "\n",
    "    return loudness_normalized_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loudness_stats(sa, sr):\n",
    "  # Return mean and max loudness given a speeach array and sample rate\n",
    "  # Credit: https://stackoverflow.com/questions/64913424/how-to-compute-loudness-from-audio-signal\n",
    "  # Compute the spectrogram (magnitude)\n",
    "  n_fft = 2048\n",
    "  hop_length = 1024\n",
    "  spec_mag = abs(librosa.stft(sa, n_fft=n_fft, hop_length=hop_length))\n",
    "\n",
    "  # Convert the spectrogram into dB\n",
    "  spec_db = librosa.amplitude_to_db(spec_mag)\n",
    "\n",
    "  # Compute A-weighting values\n",
    "  freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "  a_weights = librosa.A_weighting(freqs)\n",
    "  a_weights = np.expand_dims(a_weights, axis=1)\n",
    "\n",
    "  # Apply the A-weghting to the spectrogram in dB\n",
    "  spec_dba = spec_db + a_weights\n",
    "\n",
    "  # Compute the \"loudness\" value\n",
    "  loudness = librosa.feature.rms(S=librosa.db_to_amplitude(spec_dba))\n",
    "\n",
    "  return np.mean(loudness[0]), np.max(loudness[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_row_to_table(ndx=None, wandb_table=None, ds=None, verbose=True, frame_offset=16_000):\n",
    "  # frame_offset = how many frames to skip  \n",
    "\n",
    "  # Grab each item of interest to log\n",
    "  #speech_array, _ = torchaudio.load(ds[\"path\"][ndx])\n",
    "  speech_array, tmp_sr = torchaudio.load(ds[\"path\"][ndx], offset=frame_offset)\n",
    "  sa = speech_array[0].numpy()\n",
    "\n",
    "  # Resample\n",
    "  sampling_rate = 16_000\n",
    "  sa = librosa.resample(np.asarray(sa), 48_000, sampling_rate)\n",
    "#   print(len(sa))\n",
    "    \n",
    "#   speech_array, tmp_sr = torchaudio.load(ds[\"path\"][ndx], offset=48_000)\n",
    "#   sa2 = speech_array[0].numpy()\n",
    "#   sa2 = librosa.resample(np.asarray(sa), 48_000, sampling_rate)\n",
    "#   print(len(sa), len(sa2))\n",
    "    \n",
    "  # Normalize by loudness  \n",
    "  sa_loud_norm = get_loudness_normalised(sa, sampling_rate)\n",
    "\n",
    "  # Index into the rest of the metadata we'll be logging\n",
    "  duration = librosa.get_duration(y=sa, sr=sampling_rate) \n",
    "  text = ds['sentence'][ndx]\n",
    "  gender = ds['gender'][ndx]\n",
    "  fn = ds['path'][ndx].split('/')[-1] \n",
    "  age = ds['age'][ndx]\n",
    "  downvotes = ds['down_votes'][ndx]\n",
    "  upvotes = ds['up_votes'][ndx]\n",
    "  accent = ds['accent'][ndx]\n",
    "\n",
    "  # Example of additional calculated audio stats\n",
    "  mean_loudness, max_loudness = get_loudness_stats(sa, sampling_rate)\n",
    "\n",
    "  # Create a Wandb Audio object to log the speech array too\n",
    "  raw_audio = wandb.Audio(data_or_path=sa, sample_rate=sampling_rate, caption=fn)\n",
    "    \n",
    "  # Create object for loudness normalized  \n",
    "  loud_norm_audio = wandb.Audio(data_or_path=sa_loud_norm, sample_rate=sampling_rate, caption=f'{fn}_ld_norm')\n",
    "\n",
    "  # Create 1 row for our table with all of the objects we wish to log\n",
    "  row = [raw_audio, loud_norm_audio, text, duration, mean_loudness, max_loudness, gender, \n",
    "         age, downvotes, upvotes, accent, sampling_rate, fn]\n",
    "\n",
    "  # Add our row to the wandb table\n",
    "  wandb_table.add_data(*row)\n",
    "\n",
    "  if verbose: \n",
    "    if ndx % 100 == 0: print(ndx)\n",
    "\n",
    "  return wandb_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for the table we will save to Artifacts\n",
    "columns = ['speech', 'speech_loud_norm', 'transcription', 'duration', 'mean_loudness', \n",
    "           'max_loudness', 'gender', 'age', 'downvotes', 'upvotes', 'accent', \n",
    "           'sampling_rate', 'filename']\n",
    "\n",
    "# Create table object\n",
    "wandb_table = wandb.Table(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n",
      "/opt/conda/lib/python3.7/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n",
      "/opt/conda/lib/python3.7/site-packages/librosa/core/convert.py:1354: RuntimeWarning: divide by zero encountered in log10\n",
      "  - 0.5 * np.log10(f_sq + const[3])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Audio must be have length greater than the block size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-87ecafe05411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Log to table, row by row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mndx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mwandb_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_row_to_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_table\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-163-2f9901fc9ea2>\u001b[0m in \u001b[0;36mlog_row_to_table\u001b[0;34m(ndx, wandb_table, ds, verbose, frame_offset)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;31m# Normalize by loudness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0msa_loud_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loudness_normalised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;31m# Index into the rest of the metadata we'll be logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-150-aee7c3e5a97d>\u001b[0m in \u001b[0;36mget_loudness_normalised\u001b[0;34m(sa, sr)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# measure the loudness first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmeter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyln\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create BS.1770 meter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloudness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrated_loudness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# loudness normalize audio to -12 dB LUFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyloudnorm/meter.py\u001b[0m in \u001b[0;36mintegrated_loudness\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[1;32m     53\u001b[0m         \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pyloudnorm/util.py\u001b[0m in \u001b[0;36mvalid_audio\u001b[0;34m(data, rate, block_size)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Audio must be have length greater than the block size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Audio must be have length greater than the block size"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "N_RAND=500\n",
    "rand_ndxs = np.random.randint(0, len(common_voice_train), N_RAND)\n",
    "ds = common_voice_train.select(rand_ndxs)\n",
    "\n",
    "# ds = common_voice_train\n",
    "\n",
    "# Log to table, row by row\n",
    "for ndx in range(len(ds)):\n",
    "  wandb_table = log_row_to_table(ndx=ndx, wandb_table=wandb_table, ds=ds, verbose=True, frame_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ManifestEntry digest: RJpcxJqs6ImVIN2vNP5RCw==>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `type` can be set to whatever makes sense for you\n",
    "audio_ds_artifact = wandb.Artifact(name=\"common-voice-ie-train\", type=\"audio-file\")\n",
    "\n",
    "# Add the table to the artifact\n",
    "audio_ds_artifact.add(wandb_table, \"train_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">train_dataset_loud_norm</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/3kh4krag\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/3kh4krag</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wandb/run-20210323_151542-3kh4krag</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 51368<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 58.67MB of 58.67MB uploaded (29.28MB deduped)\\r'), FloatProgress(value=1.0, max=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/workspace/wandb/run-20210323_151542-3kh4krag/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/workspace/wandb/run-20210323_151542-3kh4krag/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 0 media file(s), 535 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">train_dataset_loud_norm</strong>: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/3kh4krag\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/3kh4krag</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Create a wandb Run\n",
    "# providing a `name` and `job_type` are optional but it helps to organise your wandb project\n",
    "audio_ds_run = wandb.init(name='train_dataset_loud_norm', job_type='dataset_logging',\n",
    "                          project=project_name, entity=entity, reinit=True)\n",
    "\n",
    "# 2. Log the artifact to the Run\n",
    "audio_ds_run.log_artifact(audio_ds_artifact)\n",
    "\n",
    "# 3. Finish the run\n",
    "audio_ds_run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Loudness Normalised Data to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = get_loudness_normalised(speech_array[0].numpy(), sampling_rate) \n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"sentence\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    speech_array, sampling_rate = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = speech_array[0].numpy()\n",
    "    batch[\"sampling_rate\"] = sampling_rate\n",
    "    batch[\"target_text\"] = batch[\"sentence\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-ac676fc6ba2a79a2.arrow\n",
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-ede4a8063fe8da59.arrow\n"
     ]
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(speech_file_to_array_fn, remove_columns=common_voice_train.column_names)\n",
    "common_voice_test = common_voice_test.map(speech_file_to_array_fn, remove_columns=common_voice_test.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we've successfully read in all the audio files, but since we know that Common Voice is sampled at 48kHz, we need to resample the audio files to 16kHz. \n",
    "\n",
    "Let's make use of the [`librosa`](https://github.com/librosa/librosa) library to downsample the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def resample(batch):\n",
    "    batch[\"speech\"] = librosa.resample(np.asarray(batch[\"speech\"]), 48_000, 16_000)\n",
    "    batch[\"sampling_rate\"] = 16_000\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-44596a8391572b14.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-7c17899e9cae662f.arrow\n",
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-89ca53832c04f8ce.arrow\n",
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-5b0634846863055d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-081c3d6dcdcafe56.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-d922913f158218a5.arrow\n",
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-04fbd4d089160624.arrow\n",
      "Loading cached processed dataset at data/common_voice/ga-IE/6.1.0/0041e06ab061b91d0a23234a2221e87970a19cf3a81b20901474cffffeb7869f/cache-a4cf71022fabbfcc.arrow\n"
     ]
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(resample, num_proc=4)\n",
    "common_voice_test = common_voice_test.map(resample, num_proc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seemed to have worked! Let's listen to a couple of audio files to better understand the dataset and verify that the audio was correctly loaded. \n",
    "\n",
    "**Note**: *You can click the following cell a couple of times to listen to different speech samples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "rand_int = random.randint(0, len(common_voice_train)-1)\n",
    "\n",
    "ipd.Audio(data=np.asarray(common_voice_train[rand_int][\"speech\"]), autoplay=True, rate=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be heard, that the speakers change along with their speaking rate, accent, and background environment, etc. Overall, the recordings sound acceptably clear though, which is to be expected from a crowd-sourced read speech corpus.\n",
    "\n",
    "Let's do a final check that the data is correctly prepared, by printing the shape of the speech input, its transcription, and the corresponding sampling rate.\n",
    "\n",
    "**Note**: *You can click the following cell a couple of times to verify multiple samples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target text: an bord a dhíolmhú ó cheanglas i dtaobh ceadúnas paisinéirí \n",
      "Input array shape: (76800,)\n",
      "Sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "rand_int = random.randint(0, len(common_voice_train)-1)\n",
    "\n",
    "print(\"Target text:\", common_voice_train[rand_int][\"target_text\"])\n",
    "print(\"Input array shape:\", np.asarray(common_voice_train[rand_int][\"speech\"]).shape)\n",
    "print(\"Sampling rate:\", common_voice_train[rand_int][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Everything looks fine - the data is a 1-dimensional array, the sampling rate always corresponds to 16kHz, and the target text is normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can process the dataset to the format expected by the model for training. We will again make use of the `map(...)` function.\n",
    "\n",
    "First, we check that the data samples have the same sampling rate of 16kHz.\n",
    "Second, we extract the `input_values` from the loaded audio file. In our case, this includes only normalization, but for other speech models, this step could correspond to extracting, *e.g.* [Log-Mel features](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum). \n",
    "Third, we encode the transcriptions to label ids.\n",
    "\n",
    "**Note**: This mapping function is a good example of how the `Wav2Vec2Processor` class should be used. In \"normal\" context, calling `processor(...)` is redirected to `Wav2Vec2FeatureExtractor`'s call method. When wrapping the processor into the `as_target_processor` context, however, the same method is redirected to `Wav2Vec2CTCTokenizer`'s call method.\n",
    "For more information please check the [docs](https://huggingface.co/transformers/master/model_doc/wav2vec2.html#transformers.Wav2Vec2Processor.__call__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # check that all files have the correct sampling rate\n",
    "    assert (\n",
    "        len(set(batch[\"sampling_rate\"])) == 1\n",
    "    ), f\"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.\"\n",
    "\n",
    "    batch[\"input_values\"] = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0]).input_values\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"target_text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd2844a6bbb421f902e7cd8ddd17d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=33.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af9ef632ae64ff3a8208d638ef475c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=33.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ed55a8aee1469f8a2c932fa7115c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=33.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318b4dc9ee2b4a22af2d65f7fbc357d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=33.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb549d53f244b638da819ce3ccd9e00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#3', max=16.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fd6bc49ae24c8d8f4727f5b8b0322d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#0', max=16.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34be6e835ea84f41ab3700f37e135a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#1', max=16.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9faece55e747b8826f8079663b8b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='#2', max=16.0, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "common_voice_train = common_voice_train.map(prepare_dataset, remove_columns=common_voice_train.column_names, batch_size=8, num_proc=4, batched=True)\n",
    "common_voice_test = common_voice_test.map(prepare_dataset, remove_columns=common_voice_test.column_names, batch_size=8, num_proc=4, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The data is processed so that we are ready to start setting up the training pipeline. We will make use of 🤗's [Trainer](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer) for which we essentially need to do the following:\n",
    "\n",
    "- Define a data collator. In contrast to most NLP models, XLSR-Wav2Vec2 has a much larger input length than output length. *E.g.*, a sample of input length 50000 has an output length of no more than 100. Given the large input sizes, it is much more efficient to pad the training batches dynamically meaning that all training samples should only be padded to the longest sample in their batch and not the overall longest sample. Therefore, fine-tuning XLSR-Wav2Vec2 requires a special padding data collator, which we will define below\n",
    "\n",
    "- Evaluation metric. During training, the model should be evaluated on the word error rate. We should define a `compute_metrics` function accordingly\n",
    "\n",
    "- Load a pretrained checkpoint. We need to load a pretrained checkpoint and configure it correctly for training.\n",
    "\n",
    "- Define the training configuration.\n",
    "\n",
    "After having fine-tuned the model, we will correctly evaluate it on the test data and verify that it has indeed learned to correctly transcribe speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up Trainer\n",
    "\n",
    "Let's start by defining the data collator. The code for the data collator was copied from [this example](https://github.com/huggingface/transformers/blob/9a06b6b11bdfc42eea08fa91d0c737d1863c99e3/examples/research_projects/wav2vec2/run_asr.py#L81).\n",
    "\n",
    "Without going into too many details, in contrast to the common data collators, this data collator treats the `input_values` and `labels` differently and thus applies to separate padding functions on them (again making use of XLSR-Wav2Vec2's context manager). This is necessary because in speech input and output are of different modalities meaning that they should not be treated by the same padding function.\n",
    "Analogous to the common data collators, the padding tokens in the labels with `-100` so that those tokens are **not** taken into account when computing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True,\n",
    "                                          pad_to_multiple_of=8, pad_to_multiple_of_labels=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the evaluation metric is defined. As mentioned earlier, the \n",
    "predominant metric in ASR is the word error rate (WER), hence we will use it in this notebook as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will return a sequence of logit vectors:\n",
    "$\\mathbf{y}_1, \\ldots, \\mathbf{y}_m$ with $\\mathbf{y}_1 = f_{\\theta}(x_1, \\ldots, x_n)[0]$ and $n >> m$.\n",
    "\n",
    "A logit vector $\\mathbf{y}_1$ contains the log-odds for each word in the vocabulary we defined earlier, thus $\\text{len}(\\mathbf{y}_i) =$ `config.vocab_size`. We are interested in the most likely prediction of the model and thus take the `argmax(...)` of the logits. Also, we transform the encoded labels back to the original string by replacing `-100` with the `pad_token_id` and decoding the ids while making sure that consecutive tokens are **not** grouped to the same token in CTC style ${}^1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load the pretrained `XLSR-Wav2Vec2` checkpoint. The tokenizer's `pad_token_id` must be to define the model's `pad_token_id` or in the case of `Wav2Vec2ForCTC` also CTC's *blank token* ${}^2$. To save GPU memory, we enable PyTorch's [gradient checkpointing](https://pytorch.org/docs/stable/checkpoint.html) and also set the loss reduction to \"*mean*\".\n",
    "\n",
    "Because the dataset is quite small (~6h of training data) and because Common Voice is quite noisy, fine-tuning Facebook's [wav2vec2-large-xlsr-53 checkpoint](https://huggingface.co/facebook/wav2vec2-large-xlsr-53) seems to require some hyper-parameter tuning. Therefore, I had to play around a bit with different values for dropout, [SpecAugment](https://arxiv.org/abs/1904.08779)'s masking dropout rate, layer dropout, and the learning rate until training seemed to be stable enough. \n",
    "\n",
    "**Note**: When using this notebook to train XLSR-Wav2Vec2 on another language of Common Voice those hyper-parameter settings might not work very well. Feel free to adapt those depending on your use case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component of XLSR-Wav2Vec2 consists of a stack of CNN layers that are used to extract acoustically meaningful - but contextually independent - features from the raw speech signal. This part of the model has already been sufficiently trained during pretraining and as stated in the [paper](https://arxiv.org/pdf/2006.13979.pdf) does not need to be fine-tuned anymore. \n",
    "Thus, we can set the `requires_grad` to `False` for all parameters of the *feature extraction* part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a final step, we define all parameters related to training. \n",
    "To give more explanation on some of the parameters:\n",
    "- `group_by_length` makes training more efficient by grouping training samples of similar input length into one batch. This can significantly speed up training time by heavily reducing the overall number of useless padding tokens that are passed through the model\n",
    "- `learning_rate` and `weight_decay` were heuristically tuned until fine-tuning has become stable. Note that those parameters strongly depend on the Common Voice dataset and might be suboptimal for other speech datasets.\n",
    "\n",
    "For more explanations on other parameters, one can take a look at the [docs](https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer#trainingarguments).\n",
    "\n",
    "**Note**: If one wants to save the trained models in his/her google drive the commented-out `output_dir` can be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=\"data\",\n",
    "  # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=32,\n",
    "  per_device_eval_batch_size=64,\n",
    "  gradient_accumulation_steps=1,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  fp16=True,\n",
    "  save_steps=25,\n",
    "  eval_steps=25,\n",
    "  logging_steps=5,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=200,\n",
    "  save_total_limit=1,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "  run_name = 'ie-base-50e-ovh-4-4-upgrade',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all instances can be passed to Trainer and we are ready to start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "${}^1$ To allow models to become independent of the speaker rate, in CTC, consecutive tokens that are identical are simply grouped as a single token. However, the encoded labels should not be grouped when decoding since they don't correspond to the predicted tokens of the model, which is why the `group_tokens=False` parameter has to be passed. If we wouldn't pass this parameter a word like `\"hello\"` would incorrectly be encoded, and decoded as `\"helo\"`.\n",
    "\n",
    "${}^2$ The blank token allows the model to predict a word, such as `\"hello\"` by forcing it to insert the blank token between the two l's. A CTC-conform prediction of `\"hello\"` of our model would be `[PAD] [PAD] \"h\" \"e\" \"e\" \"l\" \"l\" [PAD] \"l\" \"o\" \"o\" [PAD]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training will take between 180 and 240 minutes depending on the GPU allocated to this notebook. While the trained model yields somewhat satisfying results on *Common Voice*'s test data of Turkish, it is by no means an optimally fine-tuned model. The purpose of this notebook is to demonstrate how XLSR-Wav2Vec2's [checkpoint](https://huggingface.co/facebook/wav2vec2-large-xlsr-53) can be fine-tuned on a low-resource ASR dataset.\n",
    "\n",
    "In case you want to use this google colab to fine-tune your model, you should make sure that your training doesn't stop due to inactivity. A simple hack to prevent this is to paste the following code into the console of this tab (*right mouse click -> inspect -> Console tab and insert code*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```javascript\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
    "}\n",
    "setInterval(ConnectButton,60000);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                                        Size  Used Avail Use% Mounted on\n",
      "overlay                                           388G  126G  263G  33% /\n",
      "tmpfs                                              64M     0   64M   0% /dev\n",
      "tmpfs                                              87G     0   87G   0% /sys/fs/cgroup\n",
      "/dev/sda1                                         388G  126G  263G  33% /home\n",
      "10.98.115.129,10.97.15.129,10.97.7.129:/ovh/data  8.6T  274G  8.3T   4% /workspace/data\n",
      "tmpfs                                              87G   56K   87G   1% /dev/shm\n",
      "tmpfs                                              87G   12K   87G   1% /proc/driver/nvidia\n",
      "udev                                               87G     0   87G   0% /dev/nvidia1\n",
      "tmpfs                                              87G     0   87G   0% /proc/acpi\n",
      "tmpfs                                              87G     0   87G   0% /proc/scsi\n",
      "tmpfs                                              87G     0   87G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie-base-50e-ovh-4-4-upgrade</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/17jq6qjl\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/17jq6qjl</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wandb/run-20210322_213555-17jq6qjl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 2:25:59, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>16.910900</td>\n",
       "      <td>19.851835</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.199500</td>\n",
       "      <td>10.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>11.013100</td>\n",
       "      <td>9.274652</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.676000</td>\n",
       "      <td>10.186000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>3.909600</td>\n",
       "      <td>3.731420</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.708100</td>\n",
       "      <td>10.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.116000</td>\n",
       "      <td>3.093797</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.602700</td>\n",
       "      <td>10.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.027200</td>\n",
       "      <td>3.029405</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.286700</td>\n",
       "      <td>10.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.985200</td>\n",
       "      <td>2.969006</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.159000</td>\n",
       "      <td>10.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.995400</td>\n",
       "      <td>2.992875</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.755800</td>\n",
       "      <td>10.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.964600</td>\n",
       "      <td>2.920878</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>51.081200</td>\n",
       "      <td>9.906000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.918800</td>\n",
       "      <td>2.924300</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.780900</td>\n",
       "      <td>10.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.922700</td>\n",
       "      <td>2.950752</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.190600</td>\n",
       "      <td>10.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.897700</td>\n",
       "      <td>2.892996</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.875900</td>\n",
       "      <td>10.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.977900</td>\n",
       "      <td>2.902837</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.682500</td>\n",
       "      <td>9.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.888700</td>\n",
       "      <td>2.866564</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>51.886900</td>\n",
       "      <td>9.752000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.746400</td>\n",
       "      <td>2.635600</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.897400</td>\n",
       "      <td>10.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.425900</td>\n",
       "      <td>2.277162</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>52.704200</td>\n",
       "      <td>9.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.892100</td>\n",
       "      <td>1.785602</td>\n",
       "      <td>0.984786</td>\n",
       "      <td>50.220700</td>\n",
       "      <td>10.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.633600</td>\n",
       "      <td>1.382392</td>\n",
       "      <td>0.955822</td>\n",
       "      <td>50.287000</td>\n",
       "      <td>10.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.298900</td>\n",
       "      <td>1.184137</td>\n",
       "      <td>0.829432</td>\n",
       "      <td>54.454600</td>\n",
       "      <td>9.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>1.131942</td>\n",
       "      <td>0.787303</td>\n",
       "      <td>55.295700</td>\n",
       "      <td>9.151000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.866400</td>\n",
       "      <td>1.047049</td>\n",
       "      <td>0.768578</td>\n",
       "      <td>54.032200</td>\n",
       "      <td>9.365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>1.055920</td>\n",
       "      <td>0.743417</td>\n",
       "      <td>55.441700</td>\n",
       "      <td>9.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.716200</td>\n",
       "      <td>1.031850</td>\n",
       "      <td>0.735810</td>\n",
       "      <td>50.515700</td>\n",
       "      <td>10.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>0.461400</td>\n",
       "      <td>1.014104</td>\n",
       "      <td>0.690755</td>\n",
       "      <td>50.152200</td>\n",
       "      <td>10.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.499600</td>\n",
       "      <td>1.025969</td>\n",
       "      <td>0.681978</td>\n",
       "      <td>51.743700</td>\n",
       "      <td>9.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>1.054192</td>\n",
       "      <td>0.708602</td>\n",
       "      <td>50.723500</td>\n",
       "      <td>9.976000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>1.057128</td>\n",
       "      <td>0.686366</td>\n",
       "      <td>50.325800</td>\n",
       "      <td>10.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>0.274300</td>\n",
       "      <td>1.151791</td>\n",
       "      <td>0.687829</td>\n",
       "      <td>50.590800</td>\n",
       "      <td>10.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.194600</td>\n",
       "      <td>1.143884</td>\n",
       "      <td>0.674078</td>\n",
       "      <td>50.980900</td>\n",
       "      <td>9.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>1.088287</td>\n",
       "      <td>0.640140</td>\n",
       "      <td>50.745000</td>\n",
       "      <td>9.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>1.117724</td>\n",
       "      <td>0.638678</td>\n",
       "      <td>51.238600</td>\n",
       "      <td>9.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>1.058805</td>\n",
       "      <td>0.629901</td>\n",
       "      <td>51.105900</td>\n",
       "      <td>9.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.154500</td>\n",
       "      <td>1.117424</td>\n",
       "      <td>0.638385</td>\n",
       "      <td>50.740500</td>\n",
       "      <td>9.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>1.138583</td>\n",
       "      <td>0.643651</td>\n",
       "      <td>50.760400</td>\n",
       "      <td>9.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>1.100966</td>\n",
       "      <td>0.630193</td>\n",
       "      <td>51.914500</td>\n",
       "      <td>9.747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>1.154825</td>\n",
       "      <td>0.620831</td>\n",
       "      <td>51.154500</td>\n",
       "      <td>9.892000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>1.208675</td>\n",
       "      <td>0.631363</td>\n",
       "      <td>51.126300</td>\n",
       "      <td>9.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>1.168609</td>\n",
       "      <td>0.632241</td>\n",
       "      <td>53.086600</td>\n",
       "      <td>9.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.124300</td>\n",
       "      <td>1.202987</td>\n",
       "      <td>0.626097</td>\n",
       "      <td>51.424600</td>\n",
       "      <td>9.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.145700</td>\n",
       "      <td>1.183988</td>\n",
       "      <td>0.615272</td>\n",
       "      <td>51.485800</td>\n",
       "      <td>9.828000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>1.211649</td>\n",
       "      <td>0.617905</td>\n",
       "      <td>53.008000</td>\n",
       "      <td>9.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>1.232898</td>\n",
       "      <td>0.617613</td>\n",
       "      <td>51.768600</td>\n",
       "      <td>9.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.117500</td>\n",
       "      <td>1.198322</td>\n",
       "      <td>0.603862</td>\n",
       "      <td>51.660600</td>\n",
       "      <td>9.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>1.210388</td>\n",
       "      <td>0.604740</td>\n",
       "      <td>51.189000</td>\n",
       "      <td>9.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.159600</td>\n",
       "      <td>1.244329</td>\n",
       "      <td>0.610591</td>\n",
       "      <td>51.254300</td>\n",
       "      <td>9.872000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.153600</td>\n",
       "      <td>1.201496</td>\n",
       "      <td>0.603862</td>\n",
       "      <td>51.552000</td>\n",
       "      <td>9.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>1.330979</td>\n",
       "      <td>0.614102</td>\n",
       "      <td>51.871300</td>\n",
       "      <td>9.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>1.274745</td>\n",
       "      <td>0.608543</td>\n",
       "      <td>51.746700</td>\n",
       "      <td>9.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>1.293233</td>\n",
       "      <td>0.620831</td>\n",
       "      <td>52.096700</td>\n",
       "      <td>9.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>1.311805</td>\n",
       "      <td>0.614980</td>\n",
       "      <td>51.488800</td>\n",
       "      <td>9.827000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>1.262385</td>\n",
       "      <td>0.598303</td>\n",
       "      <td>52.241100</td>\n",
       "      <td>9.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>1.259497</td>\n",
       "      <td>0.601814</td>\n",
       "      <td>51.024400</td>\n",
       "      <td>9.917000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>1.262543</td>\n",
       "      <td>0.596255</td>\n",
       "      <td>53.089400</td>\n",
       "      <td>9.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.167000</td>\n",
       "      <td>1.270383</td>\n",
       "      <td>0.596255</td>\n",
       "      <td>53.679500</td>\n",
       "      <td>9.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>1.286125</td>\n",
       "      <td>0.599473</td>\n",
       "      <td>53.632200</td>\n",
       "      <td>9.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>1.300773</td>\n",
       "      <td>0.599766</td>\n",
       "      <td>52.186700</td>\n",
       "      <td>9.696000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>1.314763</td>\n",
       "      <td>0.602692</td>\n",
       "      <td>51.011000</td>\n",
       "      <td>9.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.089700</td>\n",
       "      <td>1.315718</td>\n",
       "      <td>0.590696</td>\n",
       "      <td>52.855800</td>\n",
       "      <td>9.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.312548</td>\n",
       "      <td>0.602984</td>\n",
       "      <td>52.109800</td>\n",
       "      <td>9.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>1.315958</td>\n",
       "      <td>0.600059</td>\n",
       "      <td>51.060300</td>\n",
       "      <td>9.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.059700</td>\n",
       "      <td>1.295234</td>\n",
       "      <td>0.596840</td>\n",
       "      <td>51.144200</td>\n",
       "      <td>9.894000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>1.290017</td>\n",
       "      <td>0.590111</td>\n",
       "      <td>51.837800</td>\n",
       "      <td>9.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>1.300187</td>\n",
       "      <td>0.591281</td>\n",
       "      <td>52.421800</td>\n",
       "      <td>9.652000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>1.299748</td>\n",
       "      <td>0.592452</td>\n",
       "      <td>52.198700</td>\n",
       "      <td>9.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>1.301730</td>\n",
       "      <td>0.591867</td>\n",
       "      <td>51.750500</td>\n",
       "      <td>9.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>1.294062</td>\n",
       "      <td>0.592744</td>\n",
       "      <td>52.159500</td>\n",
       "      <td>9.701000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>1.296774</td>\n",
       "      <td>0.593915</td>\n",
       "      <td>52.041200</td>\n",
       "      <td>9.723000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1650, training_loss=1.3173199103456554, metrics={'train_runtime': 8759.7664, 'train_samples_per_second': 0.188, 'total_flos': 6.579265506797722e+18, 'epoch': 50.0, 'init_mem_cpu_alloc_delta': 58580, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18306, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 0, 'train_mem_gpu_alloc_delta': 5058206720, 'train_mem_cpu_peaked_delta': 0, 'train_mem_gpu_peaked_delta': 0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38215<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1203.68MB of 1203.68MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/workspace/wandb/run-20210322_213555-17jq6qjl/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/workspace/wandb/run-20210322_213555-17jq6qjl/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.0835</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/epoch</td><td>50.0</td></tr><tr><td>_runtime</td><td>8760</td></tr><tr><td>_timestamp</td><td>1616457715</td></tr><tr><td>_step</td><td>1650</td></tr><tr><td>eval/loss</td><td>1.29677</td></tr><tr><td>eval/wer</td><td>0.59391</td></tr><tr><td>eval/runtime</td><td>52.0412</td></tr><tr><td>eval/samples_per_second</td><td>9.723</td></tr><tr><td>train/train_runtime</td><td>8759.7664</td></tr><tr><td>train/train_samples_per_second</td><td>0.188</td></tr><tr><td>train/total_flos</td><td>6.579265506797722e+18</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▃▅▆▇███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>█▄▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/wer</td><td>██████████▇▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▁▁▂▁▁▁▂▁▂▂██▂▄▂▂▂▃▂▄▃▅▃▄▃▃▄▄▃▃▅▆▃▅▃▄▄▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▇██▇███▇█▇▇▁▁▇▅▇▇▇▆▇▅▆▄▆▅▅▆▅▅▆▆▄▃▆▄▆▅▄▅▅</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ie-base-50e-ovh-4-4-upgrade</strong>: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/17jq6qjl\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/17jq6qjl</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem                                        Size  Used Avail Use% Mounted on\n",
      "overlay                                           388G  129G  259G  34% /\n",
      "tmpfs                                              64M     0   64M   0% /dev\n",
      "tmpfs                                              87G     0   87G   0% /sys/fs/cgroup\n",
      "/dev/sda1                                         388G  129G  259G  34% /home\n",
      "10.98.115.129,10.97.15.129,10.97.7.129:/ovh/data  8.6T  287G  8.3T   4% /workspace/data\n",
      "tmpfs                                              87G   80K   87G   1% /dev/shm\n",
      "tmpfs                                              87G   12K   87G   1% /proc/driver/nvidia\n",
      "udev                                               87G     0   87G   0% /dev/nvidia1\n",
      "tmpfs                                              87G     0   87G   0% /proc/acpi\n",
      "tmpfs                                              87G     0   87G   0% /proc/scsi\n",
      "tmpfs                                              87G     0   87G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training loss goes down and we can see that the WER on the test set also improves nicely. Because this notebook is just for demonstration purposes, we can stop here.\n",
    "\n",
    "The resulting model of this notebook has been saved to [`patrickvonplaten/wav2vec2-large-xlsr-turkish-demo`](https://huggingface.co/patrickvonplaten/wav2vec2-large-xlsr-turkish-demo)\n",
    "\n",
    "As a final check, let's load the model and verify that it indeed has learned to transcribe Turkish speech.\n",
    "\n",
    "Let's first load the pretrained checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"data\",\n",
    "  # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=32,\n",
    "  per_device_eval_batch_size=64,\n",
    "  gradient_accumulation_steps=1,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  fp16=True,\n",
    "  save_steps=25,\n",
    "  eval_steps=25,\n",
    "  logging_steps=5,\n",
    "  learning_rate=1e-4,\n",
    "  warmup_steps=100,\n",
    "  save_total_limit=1,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "  run_name = 'ie1e-4-100w-50e-ovh-4-4-upgrade',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie1e-4-100w-50e-ovh-4-4-upgrade</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/35m5a15b\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/35m5a15b</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wandb/run-20210323_000310-35m5a15b</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 2:28:41, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>16.784000</td>\n",
       "      <td>19.620174</td>\n",
       "      <td>0.998245</td>\n",
       "      <td>51.626700</td>\n",
       "      <td>9.801000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>15.071400</td>\n",
       "      <td>18.899715</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.470100</td>\n",
       "      <td>10.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>8.792200</td>\n",
       "      <td>7.581682</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.218100</td>\n",
       "      <td>10.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.581600</td>\n",
       "      <td>3.452944</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.533300</td>\n",
       "      <td>10.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.100200</td>\n",
       "      <td>3.082635</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.991300</td>\n",
       "      <td>9.923000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.014100</td>\n",
       "      <td>3.002206</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>52.654900</td>\n",
       "      <td>9.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>2.968600</td>\n",
       "      <td>2.963183</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.323200</td>\n",
       "      <td>10.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.995100</td>\n",
       "      <td>2.944443</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.598100</td>\n",
       "      <td>10.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>2.930400</td>\n",
       "      <td>2.934498</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.725900</td>\n",
       "      <td>10.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.937100</td>\n",
       "      <td>2.929278</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.130900</td>\n",
       "      <td>10.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.916400</td>\n",
       "      <td>2.931020</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.412100</td>\n",
       "      <td>10.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.927800</td>\n",
       "      <td>2.914973</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.497800</td>\n",
       "      <td>10.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.913700</td>\n",
       "      <td>2.930453</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>52.416500</td>\n",
       "      <td>9.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.911500</td>\n",
       "      <td>2.903660</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>50.520100</td>\n",
       "      <td>10.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.909300</td>\n",
       "      <td>2.901131</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>51.772500</td>\n",
       "      <td>9.774000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.869100</td>\n",
       "      <td>2.880433</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.606200</td>\n",
       "      <td>10.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.869800</td>\n",
       "      <td>2.859838</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.779500</td>\n",
       "      <td>10.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.834800</td>\n",
       "      <td>2.813498</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>51.145000</td>\n",
       "      <td>9.893000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>2.624994</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.714200</td>\n",
       "      <td>10.178000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.519400</td>\n",
       "      <td>2.364450</td>\n",
       "      <td>0.999707</td>\n",
       "      <td>49.702200</td>\n",
       "      <td>10.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.170600</td>\n",
       "      <td>2.028677</td>\n",
       "      <td>0.987712</td>\n",
       "      <td>49.772800</td>\n",
       "      <td>10.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.944500</td>\n",
       "      <td>1.758777</td>\n",
       "      <td>1.013166</td>\n",
       "      <td>49.829900</td>\n",
       "      <td>10.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.542758</td>\n",
       "      <td>0.963429</td>\n",
       "      <td>49.900000</td>\n",
       "      <td>10.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.473300</td>\n",
       "      <td>1.406157</td>\n",
       "      <td>0.932709</td>\n",
       "      <td>49.908200</td>\n",
       "      <td>10.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.285400</td>\n",
       "      <td>1.300028</td>\n",
       "      <td>0.882680</td>\n",
       "      <td>49.840800</td>\n",
       "      <td>10.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.116600</td>\n",
       "      <td>1.243172</td>\n",
       "      <td>0.864833</td>\n",
       "      <td>49.828900</td>\n",
       "      <td>10.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.041200</td>\n",
       "      <td>1.191273</td>\n",
       "      <td>0.843768</td>\n",
       "      <td>49.978400</td>\n",
       "      <td>10.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.897800</td>\n",
       "      <td>1.168799</td>\n",
       "      <td>0.807197</td>\n",
       "      <td>49.913700</td>\n",
       "      <td>10.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>0.982100</td>\n",
       "      <td>1.122921</td>\n",
       "      <td>0.785840</td>\n",
       "      <td>50.242500</td>\n",
       "      <td>10.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.763900</td>\n",
       "      <td>1.096007</td>\n",
       "      <td>0.789936</td>\n",
       "      <td>50.221500</td>\n",
       "      <td>10.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>1.074960</td>\n",
       "      <td>0.763312</td>\n",
       "      <td>50.546400</td>\n",
       "      <td>10.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>1.050267</td>\n",
       "      <td>0.741954</td>\n",
       "      <td>50.159000</td>\n",
       "      <td>10.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.696600</td>\n",
       "      <td>1.066875</td>\n",
       "      <td>0.746050</td>\n",
       "      <td>50.127200</td>\n",
       "      <td>10.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>1.045970</td>\n",
       "      <td>0.737273</td>\n",
       "      <td>50.309900</td>\n",
       "      <td>10.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.659300</td>\n",
       "      <td>1.075299</td>\n",
       "      <td>0.759801</td>\n",
       "      <td>50.076900</td>\n",
       "      <td>10.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>1.042072</td>\n",
       "      <td>0.729666</td>\n",
       "      <td>50.361100</td>\n",
       "      <td>10.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.634900</td>\n",
       "      <td>1.023295</td>\n",
       "      <td>0.713283</td>\n",
       "      <td>50.203200</td>\n",
       "      <td>10.079000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1.055638</td>\n",
       "      <td>0.722060</td>\n",
       "      <td>50.321700</td>\n",
       "      <td>10.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.548500</td>\n",
       "      <td>1.015181</td>\n",
       "      <td>0.710064</td>\n",
       "      <td>52.417200</td>\n",
       "      <td>9.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.539000</td>\n",
       "      <td>1.018952</td>\n",
       "      <td>0.706554</td>\n",
       "      <td>50.215200</td>\n",
       "      <td>10.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>1.036254</td>\n",
       "      <td>0.702750</td>\n",
       "      <td>50.309600</td>\n",
       "      <td>10.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.569600</td>\n",
       "      <td>1.022944</td>\n",
       "      <td>0.687829</td>\n",
       "      <td>52.623400</td>\n",
       "      <td>9.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.558700</td>\n",
       "      <td>1.018984</td>\n",
       "      <td>0.684026</td>\n",
       "      <td>50.330100</td>\n",
       "      <td>10.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>1.007001</td>\n",
       "      <td>0.693681</td>\n",
       "      <td>50.413700</td>\n",
       "      <td>10.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1125</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>1.037667</td>\n",
       "      <td>0.695436</td>\n",
       "      <td>50.574100</td>\n",
       "      <td>10.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.603900</td>\n",
       "      <td>1.074043</td>\n",
       "      <td>0.702750</td>\n",
       "      <td>52.563000</td>\n",
       "      <td>9.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>1.023878</td>\n",
       "      <td>0.693973</td>\n",
       "      <td>52.577500</td>\n",
       "      <td>9.624000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>1.031776</td>\n",
       "      <td>0.691925</td>\n",
       "      <td>52.467500</td>\n",
       "      <td>9.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1225</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>1.019144</td>\n",
       "      <td>0.685781</td>\n",
       "      <td>50.337300</td>\n",
       "      <td>10.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>1.020124</td>\n",
       "      <td>0.678760</td>\n",
       "      <td>50.369500</td>\n",
       "      <td>10.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1275</td>\n",
       "      <td>0.442900</td>\n",
       "      <td>1.023439</td>\n",
       "      <td>0.681685</td>\n",
       "      <td>51.129100</td>\n",
       "      <td>9.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.426900</td>\n",
       "      <td>1.019412</td>\n",
       "      <td>0.678174</td>\n",
       "      <td>50.380800</td>\n",
       "      <td>10.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1325</td>\n",
       "      <td>0.586800</td>\n",
       "      <td>1.051660</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>50.409900</td>\n",
       "      <td>10.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.427100</td>\n",
       "      <td>1.052357</td>\n",
       "      <td>0.685489</td>\n",
       "      <td>50.418300</td>\n",
       "      <td>10.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1375</td>\n",
       "      <td>0.452600</td>\n",
       "      <td>1.050025</td>\n",
       "      <td>0.679345</td>\n",
       "      <td>50.677600</td>\n",
       "      <td>9.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>1.048839</td>\n",
       "      <td>0.672030</td>\n",
       "      <td>50.399300</td>\n",
       "      <td>10.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1425</td>\n",
       "      <td>0.486300</td>\n",
       "      <td>1.036102</td>\n",
       "      <td>0.670568</td>\n",
       "      <td>52.678300</td>\n",
       "      <td>9.605000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.293700</td>\n",
       "      <td>1.050599</td>\n",
       "      <td>0.673201</td>\n",
       "      <td>52.650700</td>\n",
       "      <td>9.611000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1475</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>1.043226</td>\n",
       "      <td>0.666179</td>\n",
       "      <td>52.896100</td>\n",
       "      <td>9.566000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>1.048260</td>\n",
       "      <td>0.673786</td>\n",
       "      <td>50.514200</td>\n",
       "      <td>10.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1525</td>\n",
       "      <td>0.319300</td>\n",
       "      <td>1.042746</td>\n",
       "      <td>0.668520</td>\n",
       "      <td>52.584300</td>\n",
       "      <td>9.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>1.047659</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>50.808000</td>\n",
       "      <td>9.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1575</td>\n",
       "      <td>0.363600</td>\n",
       "      <td>1.039763</td>\n",
       "      <td>0.665301</td>\n",
       "      <td>52.764700</td>\n",
       "      <td>9.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.228400</td>\n",
       "      <td>1.045631</td>\n",
       "      <td>0.666179</td>\n",
       "      <td>50.747100</td>\n",
       "      <td>9.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1625</td>\n",
       "      <td>0.376400</td>\n",
       "      <td>1.048252</td>\n",
       "      <td>0.663839</td>\n",
       "      <td>51.526400</td>\n",
       "      <td>9.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>1.050394</td>\n",
       "      <td>0.666179</td>\n",
       "      <td>50.422700</td>\n",
       "      <td>10.035000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38250<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1203.68MB of 1203.68MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/workspace/wandb/run-20210323_000310-35m5a15b/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/workspace/wandb/run-20210323_000310-35m5a15b/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.3555</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/epoch</td><td>50.0</td></tr><tr><td>_runtime</td><td>8923</td></tr><tr><td>_timestamp</td><td>1616466713</td></tr><tr><td>_step</td><td>1650</td></tr><tr><td>eval/loss</td><td>1.05039</td></tr><tr><td>eval/wer</td><td>0.66618</td></tr><tr><td>eval/runtime</td><td>50.4227</td></tr><tr><td>eval/samples_per_second</td><td>10.035</td></tr><tr><td>train/train_runtime</td><td>8922.7199</td></tr><tr><td>train/train_samples_per_second</td><td>0.185</td></tr><tr><td>train/total_flos</td><td>6.579265506797722e+18</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>██▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▂▅███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>██▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/wer</td><td>████████████▇█▆▅▅▃▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▁▃█▁▂▃▃▃▂▂▂▂▂▂▂▂▃▃▃▃▃▃▇▃▇▃▇▇▃▅▃▃▃██▇▄▄▃</td></tr><tr><td>eval/samples_per_second</td><td>▃█▆▁█▇▆▆▆▇▇▇▇▇▇▇▇▆▅▆▆▆▆▂▆▁▆▂▂▆▄▆▆▆▁▁▂▅▅▆</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ie1e-4-100w-50e-ovh-4-4-upgrade</strong>: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/35m5a15b\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/35m5a15b</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"data\",\n",
    "  # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=48,\n",
    "  per_device_eval_batch_size=64,\n",
    "  gradient_accumulation_steps=1,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  fp16=True,\n",
    "  save_steps=25,\n",
    "  eval_steps=25,\n",
    "  logging_steps=5,\n",
    "  learning_rate=1e-4,\n",
    "  warmup_steps=400,\n",
    "  save_total_limit=1,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "  run_name = 'ie1e-4-400w-50e-ovh-4-5-upgrade',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie1e-4-400w-50e-ovh-4-5-upgrade</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/pr9wcve2\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/pr9wcve2</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wandb/run-20210323_082025-pr9wcve2</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1100' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1100/1100 2:11:17, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>15.702500</td>\n",
       "      <td>20.250538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.413300</td>\n",
       "      <td>10.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>15.459100</td>\n",
       "      <td>20.032469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.023600</td>\n",
       "      <td>10.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>16.054300</td>\n",
       "      <td>19.705692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.322400</td>\n",
       "      <td>10.259000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>16.154700</td>\n",
       "      <td>19.339045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.047800</td>\n",
       "      <td>10.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>15.301700</td>\n",
       "      <td>18.895893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.732800</td>\n",
       "      <td>10.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>15.013600</td>\n",
       "      <td>18.419765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.260600</td>\n",
       "      <td>10.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>9.856300</td>\n",
       "      <td>6.735880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.304300</td>\n",
       "      <td>10.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.896700</td>\n",
       "      <td>3.723217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.054900</td>\n",
       "      <td>10.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.293600</td>\n",
       "      <td>3.194918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.492500</td>\n",
       "      <td>10.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.064100</td>\n",
       "      <td>3.075306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.513800</td>\n",
       "      <td>10.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>3.053900</td>\n",
       "      <td>3.016027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.887100</td>\n",
       "      <td>10.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.017100</td>\n",
       "      <td>2.949999</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.321700</td>\n",
       "      <td>10.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.968700</td>\n",
       "      <td>2.993623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.696500</td>\n",
       "      <td>10.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.940800</td>\n",
       "      <td>2.940262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.698900</td>\n",
       "      <td>10.181000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.938700</td>\n",
       "      <td>2.932228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.533900</td>\n",
       "      <td>9.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.912800</td>\n",
       "      <td>2.919930</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.978800</td>\n",
       "      <td>9.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.920800</td>\n",
       "      <td>2.915820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.825800</td>\n",
       "      <td>9.579000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.890100</td>\n",
       "      <td>2.896046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.892400</td>\n",
       "      <td>9.567000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.884200</td>\n",
       "      <td>2.884246</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.757600</td>\n",
       "      <td>9.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.913900</td>\n",
       "      <td>2.899337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.666300</td>\n",
       "      <td>9.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.822700</td>\n",
       "      <td>2.861765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.817000</td>\n",
       "      <td>9.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.727800</td>\n",
       "      <td>2.717171</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.385200</td>\n",
       "      <td>9.659000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.554500</td>\n",
       "      <td>2.467444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.229100</td>\n",
       "      <td>9.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.306500</td>\n",
       "      <td>2.168878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.478200</td>\n",
       "      <td>9.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.911100</td>\n",
       "      <td>1.824011</td>\n",
       "      <td>0.987127</td>\n",
       "      <td>53.680600</td>\n",
       "      <td>9.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.686500</td>\n",
       "      <td>1.621776</td>\n",
       "      <td>1.022528</td>\n",
       "      <td>53.223700</td>\n",
       "      <td>9.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.409500</td>\n",
       "      <td>1.411929</td>\n",
       "      <td>0.981568</td>\n",
       "      <td>50.968900</td>\n",
       "      <td>9.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.245800</td>\n",
       "      <td>1.306692</td>\n",
       "      <td>0.917203</td>\n",
       "      <td>53.715200</td>\n",
       "      <td>9.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>1.119200</td>\n",
       "      <td>1.237306</td>\n",
       "      <td>0.880925</td>\n",
       "      <td>52.299800</td>\n",
       "      <td>9.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.151800</td>\n",
       "      <td>1.196226</td>\n",
       "      <td>0.842891</td>\n",
       "      <td>50.379000</td>\n",
       "      <td>10.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>0.981400</td>\n",
       "      <td>1.130619</td>\n",
       "      <td>0.799590</td>\n",
       "      <td>49.970100</td>\n",
       "      <td>10.126000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.784900</td>\n",
       "      <td>1.123908</td>\n",
       "      <td>0.787888</td>\n",
       "      <td>49.915400</td>\n",
       "      <td>10.137000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>0.907100</td>\n",
       "      <td>1.096435</td>\n",
       "      <td>0.767408</td>\n",
       "      <td>50.258200</td>\n",
       "      <td>10.068000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>1.079041</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>50.287200</td>\n",
       "      <td>10.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875</td>\n",
       "      <td>0.704500</td>\n",
       "      <td>1.079502</td>\n",
       "      <td>0.758923</td>\n",
       "      <td>50.141400</td>\n",
       "      <td>10.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.848600</td>\n",
       "      <td>1.063557</td>\n",
       "      <td>0.757753</td>\n",
       "      <td>49.651300</td>\n",
       "      <td>10.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925</td>\n",
       "      <td>0.685500</td>\n",
       "      <td>1.065187</td>\n",
       "      <td>0.751609</td>\n",
       "      <td>50.129100</td>\n",
       "      <td>10.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.684200</td>\n",
       "      <td>1.065697</td>\n",
       "      <td>0.750146</td>\n",
       "      <td>50.317600</td>\n",
       "      <td>10.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>1.054230</td>\n",
       "      <td>0.734933</td>\n",
       "      <td>49.905800</td>\n",
       "      <td>10.139000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.685200</td>\n",
       "      <td>1.056278</td>\n",
       "      <td>0.739029</td>\n",
       "      <td>50.433700</td>\n",
       "      <td>10.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1025</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>1.060914</td>\n",
       "      <td>0.742832</td>\n",
       "      <td>50.221600</td>\n",
       "      <td>10.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>1.047898</td>\n",
       "      <td>0.727326</td>\n",
       "      <td>50.464000</td>\n",
       "      <td>10.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1075</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>1.043416</td>\n",
       "      <td>0.721182</td>\n",
       "      <td>51.303100</td>\n",
       "      <td>9.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.574400</td>\n",
       "      <td>1.045820</td>\n",
       "      <td>0.721767</td>\n",
       "      <td>50.493200</td>\n",
       "      <td>10.021000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39995<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 1203.68MB of 1203.68MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/workspace/wandb/run-20210323_082025-pr9wcve2/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/workspace/wandb/run-20210323_082025-pr9wcve2/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>0.5744</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/epoch</td><td>50.0</td></tr><tr><td>_runtime</td><td>7883</td></tr><tr><td>_timestamp</td><td>1616495509</td></tr><tr><td>_step</td><td>1100</td></tr><tr><td>eval/loss</td><td>1.04582</td></tr><tr><td>eval/wer</td><td>0.72177</td></tr><tr><td>eval/runtime</td><td>50.4932</td></tr><tr><td>eval/samples_per_second</td><td>10.021</td></tr><tr><td>train/train_runtime</td><td>7883.305</td></tr><tr><td>train/train_samples_per_second</td><td>0.14</td></tr><tr><td>train/total_flos</td><td>7.283247395753042e+18</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train/loss</td><td>█▇█▇▆▆▅▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▂▂▃▃▃▄▅▅▆▆▆▇▇███▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>█████▇▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/wer</td><td>▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▆▅▄▃▃▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▁▁▂▂▁▁▂▃▂▃▂▂▇█▆▆▅▆▅█▆▇▇▄▇▅▃▂▂▃▃▂▂▃▂▃▃▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▆██▇▇██▆▆▇▆▇▇▂▁▃▃▄▃▄▁▃▂▂▅▂▃▆▇▇▆▆▇▆▆▇▆▆▆▆</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">ie1e-4-400w-50e-ovh-4-5-upgrade</strong>: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/pr9wcve2\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/pr9wcve2</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.1,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"data\",\n",
    "  # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=48,\n",
    "  per_device_eval_batch_size=64,\n",
    "  gradient_accumulation_steps=1,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  fp16=True,\n",
    "  save_steps=25,\n",
    "  eval_steps=25,\n",
    "  logging_steps=5,\n",
    "  learning_rate=1e-4,\n",
    "  warmup_steps=100,\n",
    "  save_total_limit=1,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "  run_name = 'ie1e-4-100w-d-o',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie1e-4-100w-d-o</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/betqqchv\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/betqqchv</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wandb/run-20210323_105809-betqqchv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='841' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 841/1100 1:36:12 < 29:41, 0.15 it/s, Epoch 38.18/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>15.554500</td>\n",
       "      <td>19.991453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.343500</td>\n",
       "      <td>9.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>19.053507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.464000</td>\n",
       "      <td>10.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>13.980400</td>\n",
       "      <td>17.558977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.705100</td>\n",
       "      <td>9.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.818000</td>\n",
       "      <td>4.919689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.143100</td>\n",
       "      <td>10.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.298300</td>\n",
       "      <td>3.217547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.669200</td>\n",
       "      <td>9.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.081700</td>\n",
       "      <td>3.042261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.392100</td>\n",
       "      <td>10.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>3.028000</td>\n",
       "      <td>3.013988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.371200</td>\n",
       "      <td>10.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.980600</td>\n",
       "      <td>3.010421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.736800</td>\n",
       "      <td>9.973000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>3.003500</td>\n",
       "      <td>2.996748</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.841000</td>\n",
       "      <td>9.761000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.933300</td>\n",
       "      <td>2.951648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.574900</td>\n",
       "      <td>10.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>2.945300</td>\n",
       "      <td>2.941489</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52.292600</td>\n",
       "      <td>9.676000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.987800</td>\n",
       "      <td>2.935616</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.705100</td>\n",
       "      <td>9.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>2.911000</td>\n",
       "      <td>2.919569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.889100</td>\n",
       "      <td>9.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>2.917126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.649500</td>\n",
       "      <td>9.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>2.913700</td>\n",
       "      <td>2.914048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.028200</td>\n",
       "      <td>9.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.899700</td>\n",
       "      <td>2.904325</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.767300</td>\n",
       "      <td>9.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>2.908800</td>\n",
       "      <td>2.896867</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.809600</td>\n",
       "      <td>9.767000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.896300</td>\n",
       "      <td>2.903282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.502000</td>\n",
       "      <td>10.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>2.908000</td>\n",
       "      <td>2.893250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.926500</td>\n",
       "      <td>10.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.885900</td>\n",
       "      <td>2.895417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.275000</td>\n",
       "      <td>10.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>2.886200</td>\n",
       "      <td>2.900954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.345400</td>\n",
       "      <td>10.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.875500</td>\n",
       "      <td>2.885917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.852700</td>\n",
       "      <td>9.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>2.877500</td>\n",
       "      <td>2.871844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.598200</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.877200</td>\n",
       "      <td>2.865247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.540300</td>\n",
       "      <td>9.818000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>2.850900</td>\n",
       "      <td>2.848702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.243200</td>\n",
       "      <td>9.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.834700</td>\n",
       "      <td>2.821357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.157100</td>\n",
       "      <td>9.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>2.756300</td>\n",
       "      <td>2.725611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.221900</td>\n",
       "      <td>9.879000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.655800</td>\n",
       "      <td>2.606270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.108500</td>\n",
       "      <td>9.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725</td>\n",
       "      <td>2.532700</td>\n",
       "      <td>2.466610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.578100</td>\n",
       "      <td>10.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.477000</td>\n",
       "      <td>2.326723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.991300</td>\n",
       "      <td>9.732000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>2.323400</td>\n",
       "      <td>2.170647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.441300</td>\n",
       "      <td>9.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.132800</td>\n",
       "      <td>2.042260</td>\n",
       "      <td>0.996489</td>\n",
       "      <td>52.230900</td>\n",
       "      <td>9.688000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>2.086700</td>\n",
       "      <td>1.873823</td>\n",
       "      <td>0.981276</td>\n",
       "      <td>51.983400</td>\n",
       "      <td>9.734000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout (?) Remove \"(,),-\" and drop lr ro 3e-5 and pad to multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.1,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    gradient_checkpointing=True, \n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "  output_dir=\"data\",\n",
    "  # output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=48,\n",
    "  per_device_eval_batch_size=64,\n",
    "  gradient_accumulation_steps=1,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=50,\n",
    "  fp16=True,\n",
    "  save_steps=25,\n",
    "  eval_steps=25,\n",
    "  logging_steps=5,\n",
    "  learning_rate=1e-4,\n",
    "  warmup_steps=100,\n",
    "  save_total_limit=1,\n",
    "    \n",
    "  # WANDB LOGGING: \n",
    "  report_to = 'wandb',  # enable logging to W&B\n",
    "  run_name = 'ie1e-4-100w-d-o',   # Name your run, optional\n",
    "  load_best_model_at_end = True,  # This will ensure your best model will be uploaded to W&B\n",
    "  metric_for_best_model='wer',    # Load best model based on \"wer\", not eval loss\n",
    "  greater_is_better=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=common_voice_train,\n",
    "    eval_dataset=common_voice_test,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.23<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">ie1e-4-100w-d-o</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/wandb/xlsr-irish\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/wandb/xlsr-irish/runs/betqqchv\" target=\"_blank\">https://wandb.ai/wandb/xlsr-irish/runs/betqqchv</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/wandb/run-20210323_105809-betqqchv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='176' max='1100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 176/1100 19:03 < 1:41:12, 0.15 it/s, Epoch 7.95/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>15.554500</td>\n",
       "      <td>19.991453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.343500</td>\n",
       "      <td>9.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>19.053507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.464000</td>\n",
       "      <td>10.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>13.980400</td>\n",
       "      <td>17.558977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.705100</td>\n",
       "      <td>9.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.818000</td>\n",
       "      <td>4.919689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.143100</td>\n",
       "      <td>10.091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>3.298300</td>\n",
       "      <td>3.217547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.669200</td>\n",
       "      <td>9.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.081700</td>\n",
       "      <td>3.042261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.392100</td>\n",
       "      <td>10.041000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='7' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/8 00:38 < 00:06, 0.16 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\"patrickvonplaten/wav2vec2-large-xlsr-turkish-demo\").to(\"cuda\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"patrickvonplaten/wav2vec2-large-xlsr-turkish-demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will just take the first example of the test set, run it through the model and take the `argmax(...)` of the logits to retrieve the predicted token ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function.Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "input_dict = processor(common_voice_test[\"input_values\"][0], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "logits = model(input_dict.input_values.to(\"cuda\")).logits\n",
    "\n",
    "pred_ids = torch.argmax(logits, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We adapted `common_voice_test` quite a bit so that the dataset instance does not contain the original sentence label anymore. Thus, we re-use the original dataset to get the label of the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration tr-ad9f7b76efa9f3a0\n",
      "Reusing dataset common_voice (/root/.cache/huggingface/datasets/common_voice/tr-ad9f7b76efa9f3a0/6.1.0/32954a9015faa0d840f6c6894938545c5d12bc5d8936a80079af74bf50d71564)\n"
     ]
    }
   ],
   "source": [
    "common_voice_test_transcription = load_dataset(\"common_voice\", \"tr\", data_dir=\"./cv-corpus-6.1-2020-12-11\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can decode the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "hata küçük şeyler için birbüy bi şeyler kolaluyor ve yenekiçük şeyler için bir bimizi inciltiyoruz\n",
      "\n",
      "Reference:\n",
      "hayatta küçük şeyleri kovalıyor ve yine küçük şeyler için birbirimizi incitiyoruz.\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction:\")\n",
    "print(processor.decode(pred_ids))\n",
    "\n",
    "print(\"\\nReference:\")\n",
    "print(common_voice_test_transcription[\"sentence\"][0].lower())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! The transcription can definitely be recognized from our prediction, but it is far from being perfect. Training the model a bit longer, spending more time on the data preprocessing, and especially using a language model for decoding would certainly improve the model's overall performance. \n",
    "\n",
    "For a demonstration model on a low-resource language, the results are acceptable, however 🤗."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
