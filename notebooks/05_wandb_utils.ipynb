{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp wandbutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore \n",
    "\n",
    "> Functions to process your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#all_slow\n",
    "import wandb\n",
    "import librosa\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from fastcore.basics import *\n",
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights and Biases for EDA, Modeling Tracking and More\n",
    "\n",
    "[General Hugging Face with Weights and Biases](https://docs.wandb.ai/integrations/huggingface?utm_source=github&utm_medium=github&utm_campaign=xlsr)\n",
    "\n",
    "[Artifacts docs](https://docs.wandb.ai/artifacts?utm_source=github&utm_medium=github&utm_campaign=xlsr)\n",
    "\n",
    "[Datasets and Predictions docs](https://docs.wandb.ai/datasets-and-predictions?utm_source=github&utm_medium=github&utm_campaign=xlsr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Your Dataset with Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbDataExplorer():\n",
    "    '''\n",
    "        Pass a Hugging Face Dataset and log it to a Weigths and Biases table\n",
    "        Expects that your dataset contains a \"path\" column with file paths to \n",
    "        audio files.\n",
    "        \n",
    "        n_samples: If \"n_samples\" is less than the length of ds, a random n_samples number\n",
    "        of samples will be logged\n",
    "        \n",
    "        cols_to_log: If not set, the table will contain the following columns:\n",
    "            [audio, duration, <the rest of the columns in your dataset>...]\n",
    "    '''\n",
    "    def __init__(self, ds:Dataset=None, n_samples:int=100,  \n",
    "                 cols_to_log:list=None,resample:bool=True, new_sr:int=16_000, \n",
    "                 artifact_type:str='audio_dataset', artifact_name:str = 'my_artifact', \n",
    "                 table_name:str='explore_samples', wandb_project = 'xlsr',\n",
    "                 cols_to_exclude:list=None, verbose:bool=True):\n",
    "        store_attr()\n",
    "        self.ds_len = len(self.ds)\n",
    "        if self.n_samples < self.ds_len: \n",
    "            self.idxs = np.random.randint(0, n_samples, n_samples)\n",
    "        else:\n",
    "            self.idxs = list(range(self.ds_len))\n",
    "    \n",
    "    def _get_audio(self, path):\n",
    "        speech_array, sr = torchaudio.load(path)\n",
    "        sa = speech_array[0].numpy()\n",
    "\n",
    "        if self.resample: \n",
    "            sa = librosa.resample(np.asarray(sa), sr, self.new_sr)\n",
    "            sr = self.new_sr\n",
    "        return sa,sr\n",
    "    \n",
    "    def _make_row(self, ndx:int):\n",
    "        '''Logs all data for that row and adds and audio and duration column''' \n",
    "        row = []\n",
    "        path = self.ds[\"path\"][ndx]\n",
    "        fn = path.split('/')[-1] \n",
    "        \n",
    "        # Grab each item of interest to log\n",
    "        sa,sr = self._get_audio(path)\n",
    "\n",
    "        # Create a Wandb Audio object to log the speech array too\n",
    "        raw_audio = wandb.Audio(data_or_path=sa, sample_rate=sr, caption=fn)\n",
    "\n",
    "        # Grab the duration of the track (in seconds)\n",
    "        duration = librosa.get_duration(y=sa, sr=sr) \n",
    "\n",
    "        row.append(raw_audio)\n",
    "        row.append(duration)\n",
    "        for col in self.cols_to_log: row.append(self.ds[col][ndx])\n",
    "        return row\n",
    "    \n",
    "    def _create_wandb_data(self):\n",
    "        if self.cols_to_log is None:             \n",
    "            self.cols_to_log = [col for col in self.ds.column_names if col not in self.cols_to_exclude]\n",
    "    \n",
    "            # Set the 3rd column to be the text column if there is one\n",
    "            for i,col in enumerate(self.cols_to_log): \n",
    "                if ('text' in col) or ('sentence' in col): \n",
    "                    self.cols_to_log.insert(0, self.cols_to_log.pop(i))\n",
    "            for i,col in enumerate(self.cols_to_log):    \n",
    "                if 'path' in col: \n",
    "                        self.cols_to_log.insert(len(self.cols_to_log)-1, self.cols_to_log.pop(i))\n",
    "        \n",
    "        # Log to table data list, row by row\n",
    "        table_data = []\n",
    "        for ndx in self.idxs:\n",
    "            table_data.append(self._make_row(ndx=ndx))\n",
    "        \n",
    "        # Create wandb table object add all data to it\n",
    "        self.table_cols = ['audio', 'duration'] + self.cols_to_log\n",
    "        self.wandb_table = wandb.Table(data=table_data, columns=self.table_cols)  \n",
    "    \n",
    "    def _log_table_to_wandb(self):\n",
    "        # `type` can be set to whatever makes sense for you\n",
    "        self.audio_ds_artifact = wandb.Artifact(name=self.artifact_name, type=self.artifact_type)\n",
    "\n",
    "        # Add the table to the artifact\n",
    "        self.audio_ds_artifact.add(self.wandb_table, self.table_name)\n",
    "        \n",
    "        # Save the artifact to \n",
    "        self.audio_ds_artifact.save(project=self.wandb_project)\n",
    "        \n",
    "    def log(self):\n",
    "        self._create_wandb_data()\n",
    "        self._log_table_to_wandb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore = WandbDataExplorer(ds=test_ds, n_samples=100, \n",
    "                            artifact_name = 'my_new_artifact', artifact_type='audio_dataset',\n",
    "                            table_name='explore_samples', wandb_project = 'xlsr',\n",
    "                            cols_to_exclude=['client_id','segment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<wandb.data_types.Audio object at 0x7fe919075ad0>, 6.84, '\"Bhí Tara Viscardi agus Meadhbh O\\'Rourke ag seinnt i ngairdín na mbláth\"', '', '', 0, '', 'ga-IE', 2, 'data/downloads/extracted/ab29a329cca022c56c2f6a514b26920e0ee09b0553fbba0978944f736ca9da51/cv-corpus-6.1-2020-12-11/ga-IE/clips/common_voice_ga-IE_21558428.mp3']\n",
      "['sentence', 'accent', 'age', 'down_votes', 'gender', 'locale', 'up_votes', 'path']\n",
      "['audio', 'duration', 'sentence', 'accent', 'age', 'down_votes', 'gender', 'locale', 'up_votes', 'path']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: View artifact at https://wandb.ai/wandb/xlsr/artifacts/audio_dataset/my_new_artifact/479258d8f9b1bfc9b9f0\n"
     ]
    }
   ],
   "source": [
    "explore.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def setup_wandb(entity='wandb', project_name='xlsr', log_model=True):\n",
    "    import wandb\n",
    "    # Set W&B user name\n",
    "    os.environ[\"WANDB_ENTITY\"] = entity\n",
    "\n",
    "    # Set W&B project name. xlsr is a public W&B project\n",
    "    os.environ[\"WANDB_PROJECT\"] = project_name\n",
    "    \n",
    "    # Log your trained model to W&B as an Artifact\n",
    "    if log_model: os.environ[\"WANDB_LOG_MODEL\"] = 'true'\n",
    "\n",
    "    wandb.login()\n",
    "    \n",
    "    return entity, project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup_wandb(entity='wandb', project_name='xlsr', log_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_aug.ipynb.\n",
      "Converted 03_training.ipynb.\n",
      "Converted 04_evaluation.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "## hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
